[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\nModern Causal Mediation Analysis",
    "section": "",
    "text": "Welcome to SER 2024!\nThis open source, reproducible vignette accompanies a half-day workshop on modern causal mediation analysis, presented at the SER 2024 annual meeting.",
    "crumbs": [
      "Welcome to SER 2024!"
    ]
  },
  {
    "objectID": "index.html#about",
    "href": "index.html#about",
    "title": "\nModern Causal Mediation Analysis",
    "section": "About this workshop",
    "text": "About this workshop\nCausal mediation analysis can provide a mechanistic understanding of how an exposure impacts an outcome, a central goal in epidemiology and health sciences. However, rapid methodologic developments coupled with few formal courses presents challenges to implementation. Beginning with an overview of classical direct and indirect effects, this workshop will present recent advances that overcome limitations of previous methods, allowing for: (i) continuous exposures, (ii) multiple, non-independent mediators, and (iii) effects identifiable in the presence of intermediate confounders affected by exposure. Emphasis will be placed on flexible, stochastic and interventional direct and indirect effects, highlighting how these may be applied to answer substantive epidemiological questions from real-world studies. Multiply robust, nonparametric estimators of these causal effects, and free and open source R packages (medshift and medoutcon) for their application, will be introduced.\nTo ensure translation to real-world data analysis, this workshop will incorporate hands-on R programming exercises to allow participants practice in implementing the statistical tools presented. It is recommended that participants have working knowledge of the basic notions of causal inference, including counterfactuals and identification (linking the causal effect to a parameter estimable from the observed data distribution). Familiarity with the R programming language is also recommended.",
    "crumbs": [
      "Welcome to SER 2024!"
    ]
  },
  {
    "objectID": "index.html#schedule",
    "href": "index.html#schedule",
    "title": "\nModern Causal Mediation Analysis",
    "section": "Tentative schedule",
    "text": "Tentative schedule\n\n08:30A-08:45A: Introductions + mediation set-up \n\n08:45A-9:15A: Controlled direct effects, natural direct/indirect effects, interventional direct/indirect effects   \n\n9:15A-9:25A: Choosing an estimand in real-world examples \n\n9:25A-10:00A: What is the EIF?! \n\n10:00A-10:30A: Break + discussion\n10:30A-11:05A: Using the EIF for estimating the natural direct effect \n\n11:05A-12:00P: Example walkthrough with R packages for effect estimation \n\n12:00A-12:30P: Wrap-up\n\nNOTE: All times listed in Central Daylight Time (CDT).",
    "crumbs": [
      "Welcome to SER 2024!"
    ]
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "\nModern Causal Mediation Analysis",
    "section": "About the instructors",
    "text": "About the instructors\nIván Díaz\nI am an Associate Professor of Biostatistics in the Department of Population Health at the NYU Grossman School of Medicine. My research focuses on the development of non-parametric statistical methods for causal inference from observational and randomized studies with complex datasets, using machine learning. This includes but is not limited to mediation analysis, methods for continuous exposures, longitudinal data including survival analysis, and efficiency guarantees with covariate adjustment in randomized trials. I am also interested in general semi-parametric theory, machine learning, and high-dimensional data.\nNima Hejazi\nI’m an Assistant Professor of Biostatistics at the Harvard T.H. Chan School of Public Health. My research program explores how advances in causal inference, statistical machine learning, and computational statistics can empower discovery in the biomedical and health sciences. The focus is on developing model-agnostic (or assumption-lean) approaches to statistical inference, emphasizing a science-first, translational perspective to methods research. Areas of recent emphasis have included causal mediation analysis, inference under outcome-dependent sampling, and sieve methods in causal machine learning. My work is usually motivated by scientific problems in clinical trials and observational studies of infectious diseases, though I’ve also explored topics ranging from environmental health to healthcare equity. I’m also passionate about open source software and reproducible, transparent data science.\nKara Rudolph\nI am an Assistant Professor of Epidemiology in the Columbia Mailman School of Public Health. My research interests are in developing and applying causal inference methods to understand social and contextual influences on mental health, substance use, and violence in disadvantaged, urban areas of the United States. My current work focuses on developing methods for transportability and mediation, and subsequently applying those methods to understand how aspects of the school and peer environments mediate relationships between neighborhood factors and adolescent drug use across populations. More generally, my work on generalizing/transporting findings from study samples to target populations and identifying subpopulations most likely to benefit from interventions contributes to efforts to optimally target available policy and program resources.",
    "crumbs": [
      "Welcome to SER 2024!"
    ]
  },
  {
    "objectID": "index.html#repro",
    "href": "index.html#repro",
    "title": "\nModern Causal Mediation Analysis",
    "section": "Reproducibility note",
    "text": "Reproducibility note\nThese workshop materials were written using the Quarto, an open-source, cross-platform technical publishing system built on RMarkdown, and the complete source is available on GitHub. This version of the book was built with R version 4.4.1 (2024-06-14), pandoc version 3.1.11, and quarto version 1.4.555. See the renv.lock file in the source repository for an up-to-date list of the packages used.",
    "crumbs": [
      "Welcome to SER 2024!"
    ]
  },
  {
    "objectID": "index.html#setup",
    "href": "index.html#setup",
    "title": "\nModern Causal Mediation Analysis",
    "section": "Setup instructions",
    "text": "Setup instructions\nR and RStudio\nR and RStudio are separate downloads and installations. R is the underlying statistical computing environment. RStudio is a graphical integrated development environment (IDE) that makes using R much easier and more interactive. You need to install R before you install RStudio.\nWindows\nIf you already have R and RStudio installed\n\nOpen RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio.\nTo check which version of R you are using, start RStudio and the first thing that appears in the console indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it. You can check here for more information on how to remove old versions from your system if you wish to do so.\nIf you don’t have R and RStudio installed\n\nDownload R from the CRAN website.\nRun the .exe file that was just downloaded\nGo to the RStudio download page\n\nUnder Installers select RStudio x.yy.zzz - Windows XP/Vista/7/8 (where x, y, and z represent version numbers)\nDouble click the file to install it\nOnce it’s installed, open RStudio to make sure it works and you don’t get any error messages.\nMac OSX\nIf you already have R and RStudio installed\n\nOpen RStudio, and click on “Help” &gt; “Check for updates”. If a new version is available, quit RStudio, and download the latest version for RStudio.\nTo check the version of R you are using, start RStudio and the first thing that appears on the terminal indicates the version of R you are running. Alternatively, you can type sessionInfo(), which will also display which version of R you are running. Go on the CRAN website and check whether a more recent version is available. If so, please download and install it.\nIf you don’t have R and RStudio installed\n\nDownload R from the CRAN website.\nSelect the .pkg file for the latest R version\nDouble click on the downloaded file to install R\nIt is also a good idea to install XQuartz (needed by some packages)\nGo to the RStudio download page\n\nUnder Installers select RStudio x.yy.zzz - Mac OS X 10.6+ (64-bit) (where x, y, and z represent version numbers)\nDouble click the file to install RStudio\nOnce it’s installed, open RStudio to make sure it works and you don’t get any error messages.\nLinux\n\nFollow the instructions for your distribution from CRAN, they provide information to get the most recent version of R for common distributions. For most distributions, you could use your package manager (e.g., for Debian/Ubuntu run sudo apt-get   install r-base, and for Fedora sudo yum install R), but we don’t recommend this approach as the versions provided by this are usually out of date. In any case, make sure you have at least R 3.3.1.\nGo to the RStudio download page\n\nUnder Installers select the version that matches your distribution, and install it with your preferred method (e.g., with Debian/Ubuntu sudo dpkg -i   rstudio-x.yy.zzz-amd64.deb at the terminal).\nOnce it’s installed, open RStudio to make sure it works and you don’t get any error messages.\n\nThese setup instructions are adapted from those written for Data Carpentry: R for Data Analysis and Visualization of Ecological Data.\nVirtual environment with renv\n\nThese instructions are intended to help with setting up the included renv virtual environment, which ensures all participants are using the same exact set of R packages (and package versions). A few important notes to keep in mind:\n\nWhen R is started from the top level of this repository, renv is activated automatically. There is no further action required on your part. If renv is not installed, it will be installed automatically (as long as you have an active internet connection).\nWhile renv is active, the R session will only have access to the packages (and their dependencies) that are listed in the renv.lock file – that is, you should not expect to have access to any other R packages that may be installed elsewhere (e.g., a global package cache) on the computing system being used.\nUpon an initial attempt, renv will prompt you to install packages listed in the renv.lock file, by printing a message like the following:\n\n\nCode# - Project '~/git/ser2024_mediation_workshop' loaded. [renv 1.0.7]\n# - One or more packages recorded in the lockfile are not installed.\n# - Use `renv::status()` for more details.\n\n\nIn any such case, please call renv::status() to review the list of packages missing and to view renv’s recommendations for fixing the issue; usually, renv::restore() will be the next step necessary to install any missing packages. Note that you do not need to manually install the packages via install.packages(), remotes::install_github(), or similar, as renv will attempt do this for you.\nWhile unnecessary for the purposes of this workshop, if you’d like to learn more about the details of how the renv virtual environment system works, the following references may be helpful:\n\nCollaborating with renv\nIntroduction to renv\n\nIn some rare cases, R packages that renv automatically tries to install as part of the renv::restore() process may fail due to missing systems-level dependencies. In such cases, a reference to the missing dependencies and system-specific instructions their installation involving, e.g., Ubuntu Linux’s apt or homebrew for macOS, will usually be displayed.",
    "crumbs": [
      "Welcome to SER 2024!"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "1  What is causal mediation analysis?",
    "section": "",
    "text": "1.1 Motivating study",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is causal mediation analysis?</span>"
    ]
  },
  {
    "objectID": "preface.html#motivating-study",
    "href": "preface.html#motivating-study",
    "title": "1  What is causal mediation analysis?",
    "section": "",
    "text": "A recent, large, multi-site trial (X:BOT) compared the effectiveness of XR-NTX to buprenorphine–naloxone (BUP-NX) in preventing relapse among those with OUD starting medication in inpatient treatment settings.\nAn analysis of potential moderators of medication effectiveness found that homeless individuals had a lower risk of relapse on XR-NTX, whereas non-homeless individuals had a lower risk of relapse on BUP-NX.\nThe effect sizes were similarly large for these groups but in opposite directions.\nThe underlying mechanisms for these differences have not yet been explored. We can to identify these mechanisms by using mediation analysis.\nWe can to use mediation analysis to explore the mechanisms underlying these differences.\n\nKey questions:\n\nDo differences in the effects of treatment (comparing two medications for opioid use disorder, naltrexone vs buprenorphine) on risk of relapse operate through mediators of adherence, opioid use, pain, and depressive symptoms? (Rudolph et al. 2020)\n\nAre those mediated effects different for homeless vs non-homeless individuals?\n\n\n\n\nRudolph, Kara, Ivan Diaz, Nima Hejazi, Mark van der Laan, Sean Luo, Matisyahu Shulman, Aimee Campbell, John Rotrosen, and Edward Nunes. 2020. “Explaining Differential Effects of Medication for Opioid Use Disorder Using a Novel Approach Incorporating Mediating Variables.” Addiction.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is causal mediation analysis?</span>"
    ]
  },
  {
    "objectID": "preface.html#what-is-causal-mediation-analysis",
    "href": "preface.html#what-is-causal-mediation-analysis",
    "title": "1  What is causal mediation analysis?",
    "section": "\n1.2 What is causal mediation analysis?",
    "text": "1.2 What is causal mediation analysis?\n\nStatistical mediation analyses assess associations between the variables. They can help you establish, for example, if the association between treatment and outcome can be mostly explained by an association between treatment and mediator\nCausal mediation analyses, on the other hand, seek to asess causal relations. For example, they help you establish whether treatment causes the outcome because it causes the mediator. To do this, causal mediation seek to understand how the paths behave under circumstances different from the observed circumstances (e.g., interventions)\n\n\n1.2.1 Why are the causal methods that we will discuss today important?\n\nAssume you are interested in the effect of treatment assignment \\(A\\) (naltrexone vs. buprenorphine) on an outcome \\(Y\\) (risk of relapse) through mediators \\(M\\) (e.g., opioid use, pain, depressive symptoms)\nWe have pre-treatment confounders \\(W\\)\n\nThere is a confounder \\(Z\\) of \\(M \\rightarrow Y\\) affected by treatment assignment (with adherence)\nWe could fit the following models: \\[\\begin{align}\n    \\E(M \\mid A=a, W=w, Z=z) & = \\gamma_0 + \\gamma_1 a + \\gamma_2 w + \\gamma_3 z \\\\\n    \\E(Y \\mid M=m, A=a, W=w, Z=z) & = \\beta_0 + \\beta_1 m + \\beta_2 a + \\beta_3 w + \\beta_4 z\n  \\end{align}\\]\n\nThe product \\(\\gamma_1 \\beta_1\\) has been proposed as a measure of the effect of \\(A\\) on \\(Y\\) through \\(M\\)\n\nCausal interpretation problems with this method: We will see that this parameter cannot be interpreted as a causal effect\n\n1.2.2 R Example:\n\nAssume we have a pre-treatment confounder of \\(Y\\) and \\(M\\), denote it with \\(W\\)\nFor simplicity, assume \\(A\\) is randomized\n\nWe’ll generate a really large sample from a data generating mechanism so that we are not concerned with sampling errors\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nNote that the indirect effect (i.e., the effect through \\(M\\)) in this example is nonzero (there is a pathway \\(A \\rightarrow Z \\rightarrow M \\rightarrow Y\\))\n\nLet’s see what the product of coefficients method would say:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nAmong other things, in this workshop:\n\nWe will provide some understanding for why the above method fails in this example\nWe will study estimators that are robust to misspecification in the above models",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is causal mediation analysis?</span>"
    ]
  },
  {
    "objectID": "preface.html#causal-mediation-models",
    "href": "preface.html#causal-mediation-models",
    "title": "1  What is causal mediation analysis?",
    "section": "\n1.3 Causal mediation models",
    "text": "1.3 Causal mediation models\nIn this workshop we will use directed acyclic graphs. We will focus on the two types of graph:\n\n1.3.1 No intermediate confounders\n\n\n\n\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\n\n1.3.2 Intermediate confounders\n\n\n\n\nDirected acyclic graph under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\nThe above graphs can be interpreted as a non-parametric structural equation model (NPSEM), also known as structural causal model (SCM):\n\\[\\begin{align}\n  W & = f_W(U_W) \\nonumber \\\\\n  A & = f_A(W, U_A) \\nonumber \\\\\n  Z & = f_Z(W, A, U_Z) \\nonumber \\\\\n  M & = f_M(W, A, Z, U_M) \\nonumber \\\\\n  Y & = f_Y(W, A, Z, M, U_Y)\n\\end{align}\\]\n\nHere \\(U=(U_W, U_A, U_Z, U_M, U_Y)\\) is a vector of all unmeasured exogenous factors affecting the system\nThe functions \\(f\\) are assumed fixed but unknown\nWe posit this model as a system of equations that nature uses to generate the data\nTherefore we leave the functions \\(f\\) unspecified (i.e., we do not know the true nature mechanisms)\nSometimes we know something: e.g., if \\(A\\) is randomized we know \\(A=f_A(U_A)\\) where \\(U_A\\) is the flip of a coin (i.e., independent of everything).",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is causal mediation analysis?</span>"
    ]
  },
  {
    "objectID": "preface.html#counterfactuals",
    "href": "preface.html#counterfactuals",
    "title": "1  What is causal mediation analysis?",
    "section": "\n1.4 Counterfactuals",
    "text": "1.4 Counterfactuals\n\nRecall that we are interested in assessing how the pathways would behave under circumstances different from the observed circumstances\nWe operationalize this idea using counterfactual random variables\nCounterfactuals are hypothetical random variables that would have been observed in an alternative world where something had happened, possibly contrary to fact \n\n\n\n1.4.1 We will use the following counterfactual variables:\n\n\n\\(Y_a\\) is a counterfactual variable in a hypothetical world where \\(\\P(A=a)=1\\) with probability one for some value \\(a\\)\n\n\n\\(Y_{a,m}\\) is the counterfactual outcome in a world where \\(\\P(A=a,M=m)=1\\)\n\n\n\\(M_a\\) is the counterfactual variable representing the mediator in a world where \\(\\P(A=a)=1\\).\n\n1.4.2 How are counterfactuals defined?\n\n\nIn the NPSEM framework, counterfactuals are quantities derived from the model.\nOnce you define a change to the causal system, that change needs to be propagated downstream.\n\nExample: modifying the system to make everyone receive XR-NTX yields counterfactual adherence, mediators, and outcomes.\n\n\nTake as example the DAG in Figure 1.2: \\[\\begin{align}\n  A    &= a \\nonumber \\\\\n  Z_a  &= f_Z(W, a, U_Z) \\nonumber \\\\\n  M_a  &= f_M(W, a, Z_a, U_M) \\nonumber \\\\\n  Y_a  &= f_Y(W, a, Z_a, M_a, U_Y)\n\\end{align}\\]\n\nWe will also be interested in joint changes to the system: \\[\\begin{align}\n  A        &= a \\nonumber \\\\\n  Z_a      &= f_Z(W, a, U_Z) \\nonumber \\\\\n  M        &= m \\nonumber \\\\\n  Y_{a,m}  &= f_Y(W, a, Z_a, m, U_Y)\n\\end{align}\\]\n\nAnd, perhaps more importantly, we will use nested counterfactuals\n\nFor example, if \\(A\\) is binary, you can think of the following counterfactual \\[\\begin{align}\n  A          &= 1 \\nonumber \\\\\n  Z_1        &= f_Z(W, 1, U_Z) \\nonumber \\\\\n  M          &= M_0 \\nonumber \\\\\n  Y_{1, M_0} &= f_Y(W, 1, Z_1, M_0, U_Y)\n\\end{align}\\]\n\n\n\\(Y_{1, M_0}\\) is interpreted as the outcome for an individual in a hypothetical world where treatment was given but the mediator was held at the value it would have taken under no treatment.\nCausal mediation effects are often defined in terms of the distribution of these nested counterfactuals.\nThat is, causal effects give you information about what would have happened in some hypothetical world where the mediator and treatment mechanisms changed.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>What is causal mediation analysis?</span>"
    ]
  },
  {
    "objectID": "effects_defn.html",
    "href": "effects_defn.html",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "",
    "text": "2.1 Controlled direct effects\n\\[\\psi_{\\text{CDE}} = \\E(Y_{1,m} - Y_{0,m})\\]",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "effects_defn.html#controlled-direct-effects",
    "href": "effects_defn.html#controlled-direct-effects",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "",
    "text": "Set the mediator to a reference value \\(M=m\\) uniformly for everyone in the population\nCompare \\(A=1\\) vs \\(A=0\\) with \\(M=m\\) fixed\n\n\n2.1.1 Identification assumptions:\n\nConfounder assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\n\nPositivity assumptions:\n\n\\(\\P(M = m \\mid A=a, W) &gt; 0 \\text{  } a.e.\\)\n\\(\\P(A=a \\mid W) &gt; 0 \\text{  } a.e.\\)\n\n\n\nUnder the above identification assumptions, the controlled direct effect can be identified: \\[\n  \\E(Y_{1,m} - Y_{0,m}) = \\E\\{ \\color{ForestGreen}{\\E(Y \\mid A=1, M=m, W) -\n    \\E(Y \\mid A=0, M=m, W)} \\}\n\\]\n\n\nFor intuition about this formula in R, let’s continue with a toy example:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFirst we fit a correct model for the outcome\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nAssume we would like the CDE at \\(m=0\\)\n\nThen we generate predictions \\[\n  \\color{ForestGreen}{\\E(Y \\mid A=1, M=m, W)} \\text{ and }\n    \\color{ForestGreen}{\\E(Y \\mid A=0, M=m, W)} \\ :\n\\]\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThen we compute the difference between the predicted values \\(\\color{ForestGreen}{\\E(Y \\mid A=1, M=m, W) - \\E(Y \\mid A=0, M=m, W)}\\), and average across values of \\(W\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.1.2 Is this the estimand I want?\n\nMakes the most sense if can intervene directly on \\(M\\)\n\nAnd can think of a policy that would set everyone to a constant level \\(m\n\\in \\mathcal{M}\\).\nJudea Pearl calls this prescriptive.\nCan you think of an example? (Air pollution, rescue inhaler dosage, hospital visits…)\nDoes not provide a decomposition of the average treatment effect into direct and indirect effects.\n\n\n\nWhat if our research question doesn’t involve intervening directly on the mediator?\nWhat if we want to decompose the average treatment effect into its direct and indirect counterparts?",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "effects_defn.html#natural-direct-and-indirect-effects",
    "href": "effects_defn.html#natural-direct-and-indirect-effects",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "\n2.2 Natural direct and indirect effects",
    "text": "2.2 Natural direct and indirect effects\nStill using the same DAG as above,\n\nRecall the definition of the nested counterfactual: \\[\\begin{equation*}\n  Y_{1, M_0} = f_Y(W, 1, M_0, U_Y)\n\\end{equation*}\\]\n\nInterpreted as the outcome for an individual in a hypothetical world where treatment was given but the mediator was held at the value it would have taken under no treatment\n\n\nRecall that, because of the definition of counterfactuals \\[\\begin{equation*}\n  Y_{1, M_1} = Y_1\n\\end{equation*}\\]\n\nThen we can decompose the average treatment effect \\(\\E(Y_1-Y_0)\\) as follows\n\\[\\begin{equation*}\n\\E[Y_{1,M_1} - Y_{0,M_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{M_1}}\n  - Y_{\\color{red}{1},\\color{blue}{M_0}}]}_{\\text{natural indirect effect}} +\n  \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{M_0}} -\n  Y_{\\color{blue}{0},\\color{red}{M_0}}]}_{\\text{natural direct effect}}\n\\end{equation*}\\]\n\nNatural direct effect (NDE): Varying treatment while keeping the mediator fixed at the value it would have taken under no treatment\nNatural indirect effect (NIE): Varying the mediator from the value it would have taken under treatment to the value it would have taken under control, while keeping treatment fixed\n\n\n2.2.1 Identification assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\\(A \\indep M_a \\mid W\\)\n\\(M_0 \\indep Y_{1,m} \\mid W\\)\nand positivity assumptions\n\n2.2.2 Cross-world independence assumption\nWhat does \\(M_0 \\indep Y_{1,m} \\mid W\\) mean?\n\nConditional on \\(W\\), knowledge of the mediator value in the absence of treatment, \\(M_0\\), provides no information about the outcome under treatment, \\(Y_{1,m}\\).\nCan you think of a data-generating mechanism that would violate this assumption?\nExample: in a randomized study, whenever we believe that treatment assignment works through adherence (i.e., almost always), we are violating this assumption (more on this later).\nCross-world assumptions are problematic for other reasons, including:\n\nYou can never design a randomized study where the assumption holds by design.\n\n\n\nIf the cross-world assumption holds, can write the NDE as a weighted average of controlled direct effects at each level of \\(M=m\\).\n\\[\n  \\E \\sum_m \\{\\E(Y_{1,m} \\mid W) - \\E(Y_{0,m} \\mid W)\\} \\P(M_{0}=m \\mid W)\n\\]\n\nIf CDE(\\(m\\)) is constant across \\(m\\), then CDE = NDE.\n\n2.2.3 Identification formula:\n\nUnder the above identification assumptions, the natural direct effect can be identified: \\[\\begin{equation*}\n  \\E(Y_{1,M_0} - Y_{0,M_0}) =\n  \\E[\\color{Goldenrod}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) -\n  \\E(Y \\mid A=0, M, W)}\\color{Goldenrod}{\\mid A=0,W\\}}]\n\\end{equation*}\\]\nThe natural indirect effect can be identified similarly.\n\nLet’s dissect this formula in R:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nFirst we fit a correct model for the outcome\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThen we generate predictions \\(\\color{ForestGreen}{\\E(Y \\mid A=1, M, W)}\n\\text{ and }\\color{ForestGreen}{\\E(Y \\mid A=0, M, W)}\\) with \\(A\\) fixed but letting \\(M\\) and \\(W\\) take their observed values\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nThen we compute the difference between the predicted values \\(\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) - \\E(Y \\mid A=0, M, W)},\\)\n\nand use this difference as a pseudo-outcome in a regression on \\(A\\) and \\(W\\): \\(\\color{Goldenrod}{\\E\\{}\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) - \\E(Y \\mid\nA=0, M, W)}\\color{Goldenrod}{\\mid A=0,W\\}}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we predict the value of this pseudo-outcome under \\(A=0\\), and average the result\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n2.2.4 Is this the estimand I want?\n\nMakes sense to intervene on \\(A\\) but not directly on \\(M\\).\nWant to understand a natural mechanism underlying an association / total effect. J. Pearl calls this descriptive.\nNDE + NIE = total effect (ATE).\nOkay with the assumptions.\n\nWhat if our data structure involves a post-treatment confounder of the mediator-outcome relationship (e.g., adherence)?\n\n\n\n\nDirected acyclic graph under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\n\n\n2.2.5 Unidentifiability of the NDE and NIE in this setting\n\nIn this example, natural direct and indirect effects are not generally point identified from observed data \\(O=(W,A,Z,M,Y)\\).\nThe reason for this is that the cross-world counterfactual assumption \\[\n  Y_{1,m} \\indep M_0 \\mid W\n\\] does not hold in the above directed acyclic graph.\n\nTo give intuition, we focus on the counterfactual outcome \\(Y_{A=1, M_{A=0}}\\).\n\nThis counterfactual outcome involves two counterfactual worlds simultaneously: one in which \\(A=1\\) for the first portion of the counterfactual outcome, and one in which \\(A=0\\) for the nested portion of the counterfactual outcome.\nSetting \\(A=1\\) induces a counterfactual treatment-induced confounder, denoted \\(Z_{A=1}\\). Setting \\(A=0\\) induces another counterfactual treatment-induced confounder, denoted \\(Z_{A=0}\\).\nThe two treatment-induced counterfactual confounders, \\(Z_{A=1}\\) and \\(Z_{A=0}\\) share unmeasured common causes, \\(U_Z\\), which creates a spurious association.\nBecause \\(Z_{A=1}\\) is causally related to \\(Y_{A=1, M=m}\\), and \\(Z_{A=0}\\) is also casually related to \\(M_{A=0}\\), the path through \\(U_Z\\) means that the backdoor criterion is not met for identification of \\(Y_{A=1, M_{A=0}}\\), i.e., \\(M_{0} \\notindep Y_{A=1, m} \\mid W\\), where \\(W\\) denotes baseline covariates.\n\n\n\n\n\n\n\nParallel worlds model of the scenario considered\n\n\n\n\n\nHowever:\n\nWe can actually actually identify the NIE/NDE in the above setting if we are willing to invoke monotonicity between a treatment and one or more binary treatment-induced confounders (Tchetgen Tchetgen and VanderWeele 2014).\nAssuming monotonicity is also sometimes referred to as assuming “no defiers” – in other words, assuming that there are no individuals who would do the opposite of the encouragement.\nMonotonicity may seem like a restrictive assumption, but may be reasonable in some common scenarios (e.g., in trials where the intervention is randomized treatment assignment and the treatment-induced confounder is whether or not treatment was actually taken – in this setting, we may feel comfortable assuming that there are no “defiers”, frequently assumed when using IVs to identify causal effects)\n\n\nTchetgen Tchetgen, Eric J, and Tyler J VanderWeele. 2014. “On Identification of Natural Direct Effects When a Confounder of the Mediator Is Directly Affected by Exposure.” Epidemiology 25 (2): 282.\nNote: CDEs are still identified in this setting. They can be identified and estimated similarly to a longitudinal data sructure with a two-time-point intervention.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "effects_defn.html#interventional-indirect-effects",
    "href": "effects_defn.html#interventional-indirect-effects",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "\n2.3 Interventional (in)direct effects",
    "text": "2.3 Interventional (in)direct effects\n\nLet \\(G_a\\) denote a random draw from the distribution of \\(M_a \\mid W\\)\n\nDefine the counterfactual \\(Y_{1,G_0}\\) as the counterfactual variable in a hypothetical world where \\(A\\) is set \\(A=1\\) and \\(M\\) is set to \\(M=G_0\\) with probability one.\n\n\n\nDefine \\(Y_{0,G_0}\\) and \\(Y_{1,G_1}\\) similarly\nThen we can define: \\[\n  \\E[Y_{1,G_1} - Y_{0,G_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\n    \\color{blue}{G_1}} - Y_{\\color{red}{1},\n    \\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\n    \\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\]\nNote that \\(\\E[Y_{1,G_1} - Y_{0,G_0}]\\) is still a total effect of treatment, even if it is different from the ATE \\(\\E[Y_{1} - Y_{0}]\\)\nWe gain in the ability to solve a problem, but lose in terms of interpretation of the causal effect (cannot decompose the ATE)\n\n\n2.3.1 An alternative definition of the effects:\n\nAbove we defined \\(G_a\\) as a random draw from the distribution of \\(M_a \\mid W\\)\n\nWhat if instead we define \\(G_a\\) as a random draw from the distribution of \\(M_a\n\\mid (Z_a,W)\\)\n\nIt turns out the indirect effect defined in this way only measures the path \\(A\\rightarrow M \\rightarrow Y\\), and not the path \\(A\\rightarrow Z\\rightarrow M\n\\rightarrow Y\\)\n\nThere may be important reasons to choose one over another (e.g., survival analyses where we want the distribution conditional on \\(Z\\), instrumental variable designs where it doesn’t make sense to condition on \\(Z\\))\n\n\n2.3.2 Identification assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A, Z\\)\n\\(A \\indep M_a \\mid W\\)\nand positivity assumptions.\n\nUnder these assumptions, the population interventional direct and indirect effect is identified: \\[\\begin{align*}\n  \\E &(Y_{a, G_{a'}}) = \\\\\n     & \\E\\left[\\color{Purple}{\\E\\left\\{\\color{Goldenrod}{\\sum_z}\n      \\color{ForestGreen}{\\E(Y \\mid A=a, Z=z, M, W)}\n      \\color{Goldenrod}{\\P(Z=z \\mid A=a, W)}\\mid A=a', W\\right\\}} \\right]\n\\end{align*}\\]\n\n\nLet’s dissect this formula in R:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nLet us compute \\(\\E(Y_{1, G_0})\\) (so that \\(a = 1\\), and \\(a'=0\\)).\n\nFirst, fit a regression model for the outcome, and compute \\(\\color{ForestGreen}{\\E(Y \\mid A=a, Z=z, M, W)}\\) for all values of \\(z\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we fit the true model for \\(Z \\mid A, W\\) and get the conditional probability that \\(Z=1\\) fixing \\(A=1\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we compute the following pseudo-outcome: \\(\\color{Goldenrod}{\\sum_z}\\color{ForestGreen}{\\E(Y \\mid A=a, Z=z, M, W)}\n\\color{Goldenrod}{\\P(Z=z \\mid A=a, w)}\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nNow we regress this pseudo-outcome on \\(A,W\\), and compute the predictions setting \\(A=0\\), that is, []\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nAnd finally, just average those predictions!\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThis was for \\((a,a')=(1,0)\\). Can do the same with \\((a,a')=(1,1)\\), and \\((a,a')=(0,0)\\) to obtain an effect decomposition\n\\[\\begin{equation*}\n  \\E[Y_{1,G_1} - Y_{0,G_0}] = \\underbrace{\\E[Y_{\\color{red}{1},\n    \\color{blue}{G_1}} -\n    Y_{\\color{red}{1},\n    \\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\n    \\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\end{equation*}\\]\n\n\n2.3.3 Is this the estimand I want?\n\nMakes sense to intervene on \\(A\\) but not directly on \\(M\\).\nGoal is to understand a descriptive type of mediation.\nOkay with the assumptions!\n\n2.3.4 But, there is an important limitation of interventional effects\nMiles (2022) recently uncovered an important limitation of these effects, which can be described as follows. The sharp mediational hull hypothesis can be defined as\n\nMiles, Caleb H. 2022. “On the Causal Interpretation of Randomized Interventional Indirect Effects.” arXiv Preprint arXiv:2203.00245. https://arxiv.org/abs/2203.00245.\n\\[\n  H_0:Y(a, M(a')) = Y(a, M(a^\\star));\\text{ for all }a, a', a^\\star \\ .\n\\]\nThe problem is that interventional effects are not guaranteed to be null when the sharp mediational hypothesis is true.\nThis could present a problem in practice if some subgroup of the population has a relationship between \\(A\\) and \\(M\\), but not between \\(M\\) and \\(Y\\). Then, another distinct subgroup of the population has a relationship between \\(M\\) and \\(Y\\) but not between \\(A\\) and \\(M\\). In such a scenario, the interventional indirect effect would be nonzero, but there would be no one person in the population whose effect of \\(A\\) on \\(Y\\) would be mediated by \\(M\\).\n\nMore details in the original paper.",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "effects_defn.html#estimand-summary",
    "href": "effects_defn.html#estimand-summary",
    "title": "2  Types of path-specific causal mediation effects",
    "section": "\n2.4 Estimand Summary",
    "text": "2.4 Estimand Summary",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Types of path-specific causal mediation effects</span>"
    ]
  },
  {
    "objectID": "how_to_choose.html",
    "href": "how_to_choose.html",
    "title": "3  How to choose an estimand: Real-world example",
    "section": "",
    "text": "3.1 Comparative effectiveness of two medications for opioid use disorder (OUD)\nMotivation: Opposite overall treatment effects for homeless versus nonhomeless participants. This application was explored in detail by Rudolph et al. (2020).",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>How to choose an estimand: Real-world example</span>"
    ]
  },
  {
    "objectID": "how_to_choose.html#comparative-effectiveness-of-two-medications-for-opioid-use-disorder-oud",
    "href": "how_to_choose.html#comparative-effectiveness-of-two-medications-for-opioid-use-disorder-oud",
    "title": "3  How to choose an estimand: Real-world example",
    "section": "",
    "text": "Rudolph, Kara, Ivan Diaz, Nima Hejazi, Mark van der Laan, Sean Luo, Matisyahu Shulman, Aimee Campbell, John Rotrosen, and Edward Nunes. 2020. “Explaining Differential Effects of Medication for Opioid Use Disorder Using a Novel Approach Incorporating Mediating Variables.” Addiction.\n\n\n3.1.1 Getting specific about the question\nTo what extent does the indirect effect through mediators of adherence, pain, and depressive symptoms explain the differences in treatment effects on OUD relapse for homeless and nonhomeless individuals?\n\nWhat estimand do we want?\n\n\nCan we set \\(M=m\\) (i.e., same value) for everyone?\nAre we interested in estimating indirect effects?\n\n\\(\\rightarrow\\) So, not controlled direct effect.\n\nDo we have an intermediate confounder?\n\nYes, and it’s important.\n\n\nDo we have a binary treatment assignment variable and a binary intermediate confounder?\n\nYes.\n\n\nCan we assume monotonicity?\n\nYes.\n\n\n\n\\(\\rightarrow\\) So, could estimate natural (in)direct effects under monotonicity.\nWhat if we don’t want to assume monotonicity, or if we do not have a binary treatment assignment variable and binary intermediate confounder?\n\\(\\rightarrow\\) Interventional direct and indirect effects.\n\nDo we want to estimate the path through treatment initiation (\\(Z\\))?\n\nYes, so, not the conditional versions of these effects.\nEstimands:\n\nDirect effect: \\(\\E(Y_{1,G_0} - Y_{0,G_0})\\)\n\nIndirect effect: \\(\\E(Y_{1,G_1} - Y_{1,G_0})\\)\n\n\n\nHere \\(G_a\\) is a draw from the distribution of \\(M_a\\mid W\\).\n\n\nNeed to incorporate multiple and continuous mediators\n\n\n\nWhat if the positivity assumption \\(\\P(A=a\\mid W)&gt;0\\) violated?\n\\(\\rightarrow\\) Can’t identify or estimate any of the above effects\n\nBut we can estimate the effect of some stochastic interventions, e.g., IPSIs\nTradeoff between feasibility and interpretation\n\n\n\nWhat if the exposure variable is continuous?\n\\(\\rightarrow\\) All the above effects are defined for binary exposures\n\nBut we can estimate the effect of some stochastic interventions\nWork in progress (including upcoming R software)\n\n\nWhat if the exposure is actually time-varying? What if the mediators and/or intermediate confounders are actually time-varying?",
    "crumbs": [
      "Identification",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>How to choose an estimand: Real-world example</span>"
    ]
  },
  {
    "objectID": "estimation_prelims.html",
    "href": "estimation_prelims.html",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "",
    "text": "4.1 Option 1: G-computation estimator\nThe first estimator of \\(\\E[ \\E(Y \\mid A=1, W) ]\\) can be obtained in a three step procedure:\nIn formulas, this estimator can be written as \\[\\frac{1}{n} \\sum_{i=1}^n \\hat{\\E}(Y \\mid A_i=1, W_i)\\]",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "estimation_prelims.html#option-1-g-computation-estimator",
    "href": "estimation_prelims.html#option-1-g-computation-estimator",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "",
    "text": "Fit a regression for \\(Y\\) on \\(A\\) and \\(W\\)\n\nUse the above regression to predict the outcome mean if everyone’s \\(A\\) is set to \\(A=1\\)\n\nAverage these predictions\n\n\n\nNote that this is just a plug-in estimator for the above formula (called the g-formula): \\(\\E[\\E(Y \\mid A=1, W)]\\)\n\nThis estimator requires that the regression model for \\(\\hat{\\E}(Y \\mid A_i=1,\nW_i)\\) is correctly specified.\nDownside: If we use machine learning for this model, we do not have general theory for computing standard errors and confidence intervals",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "estimation_prelims.html#option-2-inverse-probability-weighted-estimator",
    "href": "estimation_prelims.html#option-2-inverse-probability-weighted-estimator",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "\n4.2 Option 2: Inverse probability weighted estimator",
    "text": "4.2 Option 2: Inverse probability weighted estimator\nAn alternative method of estimation can be constructed after noticing that \\[\\E[ \\E(Y \\mid A=1, W) ] = \\E\\left[ \\frac{A}{\\P(A=1\\mid W)} Y \\right],\\] using the following procedure:\n\nFit a regression for \\(A\\) and \\(W\\)\nUse the above regression to predict the probability of treatment \\(A=1\\)\nCompute the inverse probability weights \\(A_i / \\hat{\\P}(A_i =1 \\mid W_i)\\).\nThis weight will be zero for untreated units, and the inverse of the probability of treatment for treated units.\nCompute the weighted average of the outcome: \\[\\frac{1}{n} \\sum_{i=1}^n \\frac{A_i}{\\hat{\\P}(A_i=1 \\mid W_i)} Y_i\\]\nThis estimator requires that the regression model for \\(\\hat{\\P}(A=1 \\mid W_i)\\) is correctly specified.\nDownside: If we use machine learning for this model, we do not have general theory for computing standard errors and confidence intervals",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "estimation_prelims.html#option-3-augmented-inverse-probability-weighted-estimator",
    "href": "estimation_prelims.html#option-3-augmented-inverse-probability-weighted-estimator",
    "title": "\n4  Estimation preliminaries: Review of doubly robust estimators for the ATE\n",
    "section": "\n4.3 Option 3: Augmented inverse probability weighted estimator",
    "text": "4.3 Option 3: Augmented inverse probability weighted estimator\nFortunately, we can combine these two estimators to get an estimator with improved properties.\nThe improved estimator can be seen both as a corrected (or augmented) IPW estimator:\n\\[\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\frac{A_i}{\\hat{\\P}(A_i=1 \\mid W_i)}\nY_i}_{\\text{IPW estimator}} -\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\frac{\\hat{\\E}(Y \\mid A_i=1, W_i)}\n  {\\hat{\\P}(A_i=1 \\mid W_i)}[A_i - \\hat{\\P}(A_i=1 \\mid\n  W_i)]}_{\\text{Correction term}}\n\\]\nor\n\\[\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\hat{\\E}(Y \\mid A_i=1,\n  W_i)}_{\\text{G-comp estimator}} +\n\\underbrace{\\frac{1}{n} \\sum_{i=1}^n \\frac{A_i}{\\hat{\\P}(A_i=1\\mid W_i)}\n  [Y_i - \\hat{\\E}(Y \\mid A_i=1, W_i)]}_{\\text{Correction term}}\n\\]\nThis estimator has some desirable properties:\n\nIt is robust to misspecification of at most one of the models (outcome or treatment) (Q: can you see why?)\nIt is distributed as a normal random variable as sample size grows. This allows us to easily compute confidence intervals and do hypothesis tests\nIt allows us to use machine learning to estimate the treatment and outcome regressions to alleviate model misspecification bias\n\nNext, we will work towards constructing estimators with these same properties for the mediation parameters that we have introduced.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Estimation preliminaries: Review of doubly robust estimators for the ATE</span>"
    ]
  },
  {
    "objectID": "estimation_natural_interv.html",
    "href": "estimation_natural_interv.html",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "",
    "text": "5.1 Recap: Definition and identification of the NDE\nRecall:\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment\nThis SCM is represented in the above DAG and the following causal models: \\[\\begin{align*}\n  W & = f_W(U_W) \\\\\n  A & = f_A(W, U_A) \\\\\n  M & = f_M(W, A, U_M) \\\\\n  Y & = f_Y(W, A, M, U_Y),\n\\end{align*}\\] where \\((U_W, U_A,U_M, U_Y)\\) are exogenous random errors.\nRecall that we need to assume the following to identify the above causal effects from our observed data:\nThen, the NDE is identified as \\[\n    \\psi(\\P) = \\E[\\E\\{\\E(Y \\mid A=1, M, W) - \\E(Y \\mid A=0, M, W) \\mid A=0,W\\}]\n  \\]",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "estimation_natural_interv.html#recap-definition-and-identification-of-the-nde",
    "href": "estimation_natural_interv.html#recap-definition-and-identification-of-the-nde",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "",
    "text": "Assuming a binary \\(A\\), we define the natural direct effect as: \\(\\text{NDE} = \\E(Y_{1,M_{0}} - Y_{0,M_{0}})\\).\nand the natural indirect effect as: \\(\\text{NIE} = \\E(Y_{1,M_{1}} - Y_{1,M_{0}})\\).\nThe observed data is \\(O = (W, A, M, Y)\\)\n\n\n\n\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\\(A \\indep M_a \\mid W\\)\n\\(M_0 \\indep Y_{1,m} \\mid W\\)\nand positivity assumptions",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "estimation_natural_interv.html#from-causal-to-statistical-quantities",
    "href": "estimation_natural_interv.html#from-causal-to-statistical-quantities",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.2 From causal to statistical quantities",
    "text": "5.2 From causal to statistical quantities\n\nWe have arrived at identification formulas that express quantities that we care about in terms of observable quantities\nThat is, these formulas express what would have happened in hypothetical worlds in terms of quantities observable in this world.\nThis required causal assumptions\n\nMany of these assumptions are empirically unverifiable\nWe saw an example where we could relax the cross-world assumption, at the cost of changing the parameter interpretation (when we introduced randomized interventional direct and indirect effects).\nWe also include an extra section at the end about stochastic randomized interventional direct and indirect effects, which allow us to relax the positivity assumption, also at the cost of changing the parameter interpretation.\n\n\nWe are now ready to tackle the estimation problem, i.e., how do we best learn the value of quantities that are observable?\nThe resulting estimation problem can be tackled using statistical assumptions of various degrees of strength\n\nMost of these assumptions are verifiable (e.g., a linear model)\nThus, most are unnecessary (except for convenience)\nWe have worked hard to try to satisfy the required causal assumptions\nThis is not the time to introduce unnecessary statistical assumptions\nThe estimation approach we will minimizes reliance on these statistical assumptions.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "estimation_natural_interv.html#computing-identification-formulas-if-you-know-the-true-distribution",
    "href": "estimation_natural_interv.html#computing-identification-formulas-if-you-know-the-true-distribution",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.3 Computing identification formulas if you know the true distribution",
    "text": "5.3 Computing identification formulas if you know the true distribution\n\nThe mediation parameters that we consider can be seen as a function of the joint probability distribution of observed data \\(O=(W,A,Z,M,Y)\\)\n\nFor example, under identifiability assumptions the natural direct effect is equal to \\[\n  \\psi(\\P) = \\E[\\color{Goldenrod}{\\E\\{\\color{ForestGreen}\n    {\\E(Y \\mid A=1, M, W) - \\E(Y \\mid A=0, M, W)} \\mid A=0, W \\}}]\n\\]\n\nThe notation \\(\\psi(\\P)\\) means that the parameter is a function of \\(\\P\\) – in other words, that it is a function of this joint probability distribution\nThis means that we can compute it for any distribution \\(\\P\\)\n\nFor example, if we know the true \\(\\P(W,A,M,Y)\\), we can comnpute the true value of the parameter by:\n\nComputing the conditional expectation \\(\\E(Y\\mid A=1,M=m,W=w)\\) for all values \\((m,w)\\)\n\nComputing the conditional expectation \\(\\E(Y\\mid A=0,M=m,W=w)\\) for all values \\((m,w)\\)\n\nComputing the probability \\(\\P(M=m\\mid A=0,W=w)\\) for all values \\((m,w)\\)\n\nCompute \\[\\begin{align*}\n  \\color{Goldenrod}{\\E\\{}&\\color{ForestGreen}{\\E(Y \\mid A=1, M, W) -\n    \\E(Y \\mid A=0, M, W)}\\color{Goldenrod}{\\mid A=0,W\\}} =\\\\\n  &\\color{Goldenrod}{\\sum_m\\color{ForestGreen}{\\{\\E(Y \\mid A=1, m, w) -\n    \\E(Y \\mid A=0, m, w)\\}} \\P(M=m\\mid A=0, W=w)}\n\\end{align*}\\]\n\nComputing the probability \\(\\P(W=w)\\) for all values \\(w\\)\n\nComputing the mean over all values \\(w\\)",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "estimation_natural_interv.html#plug-in-and-re-weighting-estimators",
    "href": "estimation_natural_interv.html#plug-in-and-re-weighting-estimators",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.4 Plug-in and re-weighting estimators",
    "text": "5.4 Plug-in and re-weighting estimators\n\n5.4.1 Plug-in (aka g-computation) estimator\nThe above is how you would compute the true value if you know the true distribution \\(\\P\\)\n\nThis is exactly what we did in our R examples before\nBut we can use the same logic for estimation:\n\nFit a regression to estimate, say \\(\\hat\\E(Y\\mid A=1,M=m,W=w)\\)\n\nFit a regression to estimate, say \\(\\hat\\E(Y\\mid A=0,M=m,W=w)\\)\n\nFit a regression to estimate, say \\(\\hat\\P(M=m\\mid A=0,W=w)\\)\n\nEstimate \\(\\P(W=w)\\) with the empirical distribution\nEvaluate \\[\n  \\psi(\\hat\\P) = \\hat{\\E}[\\color{RoyalBlue}{\n    \\hat{\\E}\\{\\color{Goldenrod}{\\hat\\E(Y \\mid A=1, M, W) -\n    \\hat{\\E}(Y \\mid A=0, M, W)}\\mid A=0,W\\}}]\n\\]\n\n\n\nThis is known as the G-computation estimator.\n\n5.4.2 Reweighting (aka IPW) estimators\n\n5.4.2.1 First weighted estimator (like inverse probability weighted)\n\nAn alternative expression of the parameter functional (for the NDE) is given by \\[\n  \\E \\bigg[\\color{RoyalBlue}{\\bigg\\{ \\frac{\\I(A=1)}{\\P(A=1\\mid W)}\n  \\frac{\\P(M\\mid A=0,W)}{\\P(M\\mid A=1,W)} -\n  \\frac{\\I(A=0)}{\\P(A=0\\mid W)}\\bigg\\}} \\times \\color{Goldenrod}{Y}\\bigg]\n\\]\n\nThus, you can also construct a weighted estimator as \\[\n  \\frac{1}{n} \\sum_{i=1}^n \\bigg[\\color{RoyalBlue}{\\bigg\\{\n  \\frac{\\I(A_i=1)}{\\hat{\\P}(A_i=1\\mid W_i)}\n  \\frac{\\hat{\\P}(M_i\\mid A_i=0,W_i)}{\\hat{\\P}(M_i\\mid A_i=1, W_i)} -\n  \\frac{\\I(A_i=0)}{\\hat{\\P}(A_i=0\\mid W_i)}\\bigg\\}} \\times\n  \\color{Goldenrod}{Y_i} \\bigg]\n\\]\n\n\n5.4.2.2 Second weighted estimator\n\nThe parameter functional for the NDE can also be expressed as a combination of regression and weighting: \\[\n  \\E\\bigg[\\color{RoyalBlue}{\\frac{\\I(A=0)}{\\P(A=0\\mid W)}}\n  \\times \\color{Goldenrod}{\\E(Y \\mid A=1, M, W) -\n  \\E(Y \\mid A=0, M, W)}\\bigg]\n\\]\nThus, you can also construct a weighted estimator as \\[\n  \\frac{1}{n} \\sum_{i=1}^n \\bigg[\\color{RoyalBlue}{\n  \\frac{\\I(A_i=0)}{\\hat{\\P}(A_i=0\\mid W_i)}} \\times\n  \\color{Goldenrod}{\\hat{\\E}(Y \\mid A=1, M_i, W_i) -\n  \\hat{\\E}(Y \\mid A=0, M_i, W_i)}\\bigg]\n\\]\n\n5.4.3 Implementation of g-computation and IPW estimators in practice?\n\nThere are two possible ways to do G-computation or weighted estimation:\n\nUsing parametric models for the above regressions\nUsing flexible data-adaptive regression (aka machine learning)\n\n\n\n5.4.4 Pros and cons of g-computation and IPW with parametric modeling\n\nPros:\n\nEasy to understand\nEase of implementation (standard regression software)\nCan use the Delta method or the bootstrap for computation of standard errors\n\n\nCons:\n\nUnless \\(W\\) and \\(M\\) contain very few categorical variables, it is very easy to misspecify the models\nThis can introduce sizable bias in the estimators\nThis modelling assumptions have become less necessary in the presence of data-adaptive regression tools (a.k.a., machine learning)\n\n\n\n5.4.5 Example: Bias of a parametric g-computation estimator of the NDE\n\n\nThe following R chunk provides simulation code to exemplify the bias of a parametric g-computation estimator in a simple situation\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nLet’s perform a simulation where we draw 1000 datasets from the above distribution, and compute a parametric g-computation estimator based on\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe bias also affects the confidence intervals:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\n5.4.6 Pros and cons of g-computation or IPW with data-adaptive regression\n\nPros:\n\nEasy to understand.\nAlleviate model-misspecification bias.\n\n\nCons:\n\nMight be harder to implement depending on the regression procedures used.\nNo general approaches for computation of standard errors and confidence intervals.\nFor example, the bootstrap is not guaranteed to work, and it is known to fail in some cases.\n\n\n\n5.4.7 Solution: Robust semi-parametric efficient estimation\n\nIntuitively, it combines the three above estimators to obtain an estimator with improved robustness properties\nIt offers a way to use data-adaptive regression to\n\navoid model misspecification bias,\nendow the estimators with additional robustness (e.g., multiple robustness), while\nallowing the computation of correct standard errors and confidence intervals using Gaussian approximations",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "estimation_natural_interv.html#semi-parametric-efficient-estimators-for-the-nde",
    "href": "estimation_natural_interv.html#semi-parametric-efficient-estimators-for-the-nde",
    "title": "\n5  Construction of G-computation and weighted estimators: The case of the NDE\n",
    "section": "\n5.5 Semi-parametric efficient estimators (for the NDE)",
    "text": "5.5 Semi-parametric efficient estimators (for the NDE)\n\n5.5.1 Constructing a semi-parametric efficient estimator (aka the one-step)\n\n\nHere we show the detail of how to construct an estimator for the NDE for illustration, but the construction of this estimator is a bit involved and may be complex in daily research practice\nFor practice, we will teach you how to use our packages medoutcon (and medshift, as detailed in the extra material) for automatic implementation of these estimators of the NDE and other parameters\n\nFirst, we need to introduce some notation to describe the EIF for the NDE\n\nLet \\(Q(M, W)\\) denote \\(\\E(Y\\mid A=1, M, W) - \\E(Y\\mid A=0, M, W)\\)\n\nWe can now introduce the semiparametric efficient estimator:\n\n\\[\\begin{align*}\n    \\hat{\\psi} &= \\frac{1}{n} \\sum_{i=1}^n \\color{RoyalBlue}{\\bigg\\{\n      \\frac{\\I(A_i=1)}{\\hat{\\P}(A_i=1 \\mid W_i)}\n      \\frac{\\hat{\\P}(M_i \\mid A_i=0,W)_i}{\\hat{\\P}(M_i \\mid A_i=1,W_i)} -\n      \\frac{\\I(A=0)}{\\hat{\\P}(A_i=0 \\mid W_i)}\\bigg\\}}\n      \\color{Goldenrod}{[Y_i - \\hat{\\E}(Y\\mid A_i,M_i,W_i)]} \\\\\n    &+ \\frac{1}{n} \\sum_{i=1}^n \\color{RoyalBlue}{\\frac{\\I(A=0)}{\\P(A=0 \\mid\n      W)}} \\color{Goldenrod}{\\big\\{ \\hat{Q}(M_i,W_i) -\n      \\hat{\\E}[\\hat{Q}(M_i,W_i) \\mid W_i, A_i = 0] \\big\\}} \\\\\n    &+ \\frac{1}{n} \\sum_{i=1}^n \\color{Goldenrod}{\n      \\hat{\\E}[\\hat{Q}(M_i,W_i) \\mid W_i,A_i=0]}\n\\end{align*}\\]\n\nIn this estimator, you can recognize elements from the G-computation estimator and the weighted estimators:\n\nThe third line is the G-computation estimator\nThe second line is a centered version of the second weighted estimator\nThe first line is a centered version of the first weighted estimator\n\n\nEstimating \\(\\P(M\\mid A, W)\\) is a very challenging problem when \\(M\\) is high-dimensional. But, since we have the ratio of these conditional densities, we can re-parameterize using Bayes’ rule to get something that is easier to compute: \\[\\begin{equation*}\n  \\frac{\\P(M \\mid A=0, W)}{\\P(M \\mid A=1,W)} = \\frac{\\P(A = 0 \\mid M, W)\n    \\P(A=1 \\mid W)}{\\P(A = 1 \\mid M, W) \\P(A=0 \\mid W)} \\ .\n\\end{equation*}\\]\n\n\nThus we can change the expression of the estimator a bit as follows. First, some more notation that will be useful later:\n\nLet \\(g(a\\mid w)\\) denote \\(\\P(A=a\\mid W=w)\\)\n\nLet \\(e(a\\mid m, w)\\) denote \\(\\P(A=a\\mid M=m, W=w)\\)\n\nLet \\(b(a, m, w)\\) denote \\(\\E(Y\\mid A=a, M=m, W=w)\\)\n\nThe quantity being averaged can be re-expressed as follows\n\n\\[\\begin{align*}\n    & \\color{RoyalBlue}{\\bigg\\{ \\frac{\\I(A=1)}{g(0\\mid W)}\n      \\frac{e(0\\mid M,W)}{e(1\\mid M,W)} - \\frac{\\I(A=0)}{g(0\\mid W)}\\bigg\\}}\n      \\times \\color{Goldenrod}{[Y - b(A,M,W)]} \\\\\n    &+ \\color{RoyalBlue}{\\frac{\\I(A=0)}{g(0\\mid W)}}\n      \\color{Goldenrod}{\\big\\{Q(M,W) - \\E[Q(M,W) \\mid W, A=0] \\big\\}} \\\\\n    &+ \\color{Goldenrod}{\\E[Q(M,W) \\mid W, A=0]}\n\\end{align*}\\]\n\n5.5.2 How to compute the one-step estimator (like Augmented IPW)\nFirst we will generate some data:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nRecall that the semiparametric efficient estimator can be computed in the following steps:\n\n\nFit models for \\(g(a\\mid w)\\), \\(e(a\\mid m, w)\\), and \\(b(a, m, w)\\)\n\nIn this example we will use Generalized Additive Models for tractability\nIn applied settings we recommend using an ensemble of data-adaptive regression algorithms, such as the Super Learner (van der Laan, Polley, and Hubbard 2007)\n\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCompute predictions \\(g(1\\mid w)\\), \\(g(0\\mid w)\\), \\(e(1\\mid m, w)\\), \\(e(0\\mid m, w)\\),\\(b(1, m, w)\\), \\(b(0, m, w)\\), and \\(b(a, m, w)\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCompute \\(Q(M, W)\\), fit a model for \\(\\E[Q(M,W) \\mid W,A]\\), and predict at \\(A=0\\)\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nEstimate the weights\n\\[\\begin{equation*}\n\\color{RoyalBlue}{\\bigg\\{\n  \\frac{\\I(A=1)}{g(0\\mid W)} \\frac{e(0 \\mid M,W)}{e(1 \\mid M,W)} -\n  \\frac{\\I(A=0)}{g(0\\mid W)} \\bigg\\}}\n\\end{equation*}\\] using the above predictions:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nCompute the uncentered EIF:\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nThe one step estimator is the mean of the uncentered EIF\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n\nvan der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” Statistical Applications in Genetics and Molecular Biology 6 (1).\n\n5.5.3 Performance of the one-step estimator in a small simulation study\nFirst, we create a wrapper around the estimator\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\nLet us first examine the bias\n\nThe true value is:\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nBias simulation\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\nAnd now the confidence intervals:\n\n\nPlease enable JavaScript to experience the dynamic code cell content on this page.\n\n5.5.4 On targeted minimum loss-based estimation (TMLE)\n\nThe above estimator is great because it allows us to use data-adaptive regression to avoid bias, while allowing the computation of correct standard errors\nThis estimator has a problem, though:\n\nIt can yield answers outside of the bounds of the parameter space\nE.g., if \\(Y\\) is binary, it could yield direct and indirect effects outside of \\([-1,1]\\)\n\nTo solve this, you can compute a TMLE instead (implemented in the R packages, coming up)\n\n\n\n5.5.5 On cross-fitting\n\nWhen using data-adaptive regression estimators, it is recommended to use cross-fitted estimators\nCross-fitting is similar to cross-validation:\n\nRandomly split the sample into K (e.g., K=10) subsets of equal size\nFor each of the 9/10ths of the sample, fit the regression models\nUse the out-of-sample fit to predict in the remaining 1/10th of the sample\n\n\nCross-fitting further reduces the bias of the estimators\nCross-fitting aids in guaranteeing the correctness of the standard errors and confidence intervals\nCross-fitting is implemented by default in the R packages that you will see next",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Construction of G-computation and weighted estimators: The case of the NDE</span>"
    ]
  },
  {
    "objectID": "estimation_walkthrough.html",
    "href": "estimation_walkthrough.html",
    "title": "\n6  Some R packages for estimation of the causal (in)direct effects\n",
    "section": "",
    "text": "6.1 medoutcon: Efficient estimation of natural and interventional (in)direct effects\nThe data on a single observational unit can be represented \\(O = (W, A, M, Y)\\), with the data pooled across all participants denoted \\(O_1, \\ldots, O_n\\), for a of \\(n\\) i.i.d. observations of \\(O\\). Recall the DAG from an earlier chapter, which represents the data-generating process:\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Some `R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "estimation_walkthrough.html#natural-indirect-effects",
    "href": "estimation_walkthrough.html#natural-indirect-effects",
    "title": "\n6  Some R packages for estimation of the causal (in)direct effects\n",
    "section": "\n6.2 Natural (in)direct effects",
    "text": "6.2 Natural (in)direct effects\nTo start, we will consider estimation of the natural direct and indirect effects, which, we recall, are defined as follows\n\\[\n  \\E[Y_{1,M_1} - Y_{0,M_0}] =\n    \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{M_1}} -\n    Y_{\\color{red}{1},\\color{blue}{M_0}}]}_{\\text{natural indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{M_0}} -\n    Y_{\\color{blue}{0},\\color{red}{M_0}}]}_{\\text{natural direct effect}}.\n\\]\n\nOur medoutcon R package (Hejazi, Dı́az, and Rudolph 2022; Hejazi, Rudolph, and Dı́az 2022), which accompanies Dı́az et al. (2020), implements one-step and TML estimators of both the natural and interventional (in)direct effects.\nBoth types of estimators are capable of accommodating flexible modeling strategies (e.g., ensemble machine learning) for the initial estimation of nuisance parameters.\nThe medoutcon R package uses cross-validation in initial estimation: this results in cross-validated (or “cross-fitted”) one-step and TML estimators (Klaassen 1987; Zheng and van der Laan 2011; Chernozhukov et al. 2018), which exhibit greater robustness than their non-sample-splitting analogs.\nTo this end, medoutcon integrates with the sl3 R package (Coyle et al. 2022), which is extensively documented in this book chapter (Phillips 2022; van der Laan et al. 2022).\n\n\nDı́az, Iván, Nima S Hejazi, Kara E Rudolph, and Mark J van der Laan. 2020. “Non-Parametric Efficient Causal Mediation with Intermediate Confounders.” Biometrika. https://doi.org/10.1093/biomet/asaa085.\n\nKlaassen, Chris AJ. 1987. “Consistent Estimation of the Influence Function of Locally Asymptotically Linear Estimators.” The Annals of Statistics, 1548–62.\n\nZheng, Wenjing, and Mark J van der Laan. 2011. “Cross-Validated Targeted Minimum-Loss-Based Estimation.” In Targeted Learning, 459–74. Springer.\n\nChernozhukov, Victor, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, and James Robins. 2018. “Double/Debiased Machine Learning for Treatment and Structural Parameters.” The Econometrics Journal 21 (1). https://doi.org/10.1111/ectj.12097.\n\nPhillips, Rachael V. 2022. “Super (Machine) Learning.” In Targeted Learning in R: Causal Data Science with the tlverse Software Ecosystem. Springer. https://tlverse.org/tlverse-handbook/sl3.html.\n\nvan der Laan, Mark J, Jeremy R Coyle, Nima S Hejazi, Ivana Malenica, Rachael V Phillips, and Alan E Hubbard. 2022. Targeted Learning in R: Causal Data Science with the tlverse Software Ecosystem. CRC Press. https://tlverse.org/tlverse-handbook.\n\n6.2.1 Interlude: sl3 for nuisance parameter estimation\n\nTo fully take advantage of the one-step and TML estimators, we’d like to rely on flexible, data adaptive strategies for nuisance parameter estimation.\nDoing so minimizes opportunities for model misspecification to compromise our analytic conclusions.\nChoosing among the diversity of available machine learning algorithms can be challenging, so we recommend using the Super Learner algorithm for ensemble machine learning (van der Laan, Polley, and Hubbard 2007), which is implemented in the sl3 R package (Coyle et al. 2022).\n\nBelow, we demonstrate the construction of an ensemble learner based on a limited library of algorithms, including n intercept model, a main terms GLM, Lasso (\\(\\ell_1\\)-penalized) regression, and random forest (ranger).\n\nCode# instantiate learners\nmean_lrnr &lt;- Lrnr_mean$new()\nfglm_lrnr &lt;- Lrnr_glm_fast$new()\nlasso_lrnr &lt;- Lrnr_glmnet$new(alpha = 1, nfolds = 3)\nrf_lrnr &lt;- Lrnr_ranger$new(num.trees = 200)\n\n# create learner library and instantiate super learner ensemble\nlrnr_lib &lt;- Stack$new(mean_lrnr, fglm_lrnr, lasso_lrnr, rf_lrnr)\nsl_lrnr &lt;- Lrnr_sl$new(learners = lrnr_lib, metalearner = Lrnr_nnls$new())\n\n\n\nOf course, there are many alternatives for learning algorithms to be included in such a modeling library. Feel free to explore!\n\nvan der Laan, Mark J, Eric C Polley, and Alan E Hubbard. 2007. “Super Learner.” Statistical Applications in Genetics and Molecular Biology 6 (1).\n\nCoyle, Jeremy R, Nima S Hejazi, Ivana Malenica, Rachael V Phillips, and Oleg Sofrygin. 2022. sl3: Modern Pipelines for Machine Learning and Super Learning. https://github.com/tlverse/sl3. https://doi.org/10.5281/zenodo.1342293.\n\n6.2.2 Efficient estimation of the natural (in)direct effects\n\n\nEstimation of the natural direct and indirect effects requires estimation of a few nuisance parameters. Recall that these are\n\n\n\\(g(a\\mid w)\\), which denotes \\(\\P(A=a \\mid W=w)\\)\n\n\n\\(h(a\\mid m, w)\\), which denotes \\(\\P(A=a \\mid M=m, W=w)\\)\n\n\n\\(b(a, m, w)\\), which denotes \\(\\E(Y \\mid A=a, M=m, W=w)\\)\n\n\n\nWhile we recommend the use of Super Learning, we opt to instead estimate all nuisance parameters with Lasso regression below (to save computational time).\n\nNow, let’s use the medoutcon() function to estimate the natural direct effect:\n\nCode# compute one-step estimate of the natural direct effect\nnde_onestep &lt;- medoutcon(\n  W = weight_behavior[, c(\"age\", \"sex\", \"race\", \"tvhours\")],\n  A = (as.numeric(weight_behavior$sports) - 1),\n  Z = NULL,\n  M = weight_behavior[, c(\"snack\", \"exercises\", \"overweigh\")],\n  Y = weight_behavior$bmi,\n  g_learners = lasso_lrnr,\n  h_learners = lasso_lrnr,\n  b_learners = lasso_lrnr,\n  effect = \"direct\",\n  estimator = \"onestep\",\n  estimator_args = list(cv_folds = 5)\n)\nsummary(nde_onestep)\n\n# A tibble: 1 × 7\n  lwr_ci param_est upr_ci var_est  eif_mean estimator param         \n   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;         \n1 -0.388     0.249  0.886   0.106 -6.03e-16 onestep   direct_natural\n\n\n\nWe can similarly call medoutcon() to estimate the natural indirect effect:\n\n\nCode# compute one-step estimate of the natural indirect effect\nnie_onestep &lt;- medoutcon(\n  W = weight_behavior[, c(\"age\", \"sex\", \"race\", \"tvhours\")],\n  A = (as.numeric(weight_behavior$sports) - 1),\n  Z = NULL,\n  M = weight_behavior[, c(\"snack\", \"exercises\", \"overweigh\")],\n  Y = weight_behavior$bmi,\n  g_learners = lasso_lrnr,\n  h_learners = lasso_lrnr,\n  b_learners = lasso_lrnr,\n  effect = \"indirect\",\n  estimator = \"onestep\",\n  estimator_args = list(cv_folds = 5)\n)\nsummary(nie_onestep)\n\n# A tibble: 1 × 7\n  lwr_ci param_est upr_ci var_est eif_mean estimator param           \n   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;           \n1  0.507      1.07   1.63  0.0823 3.10e-15 onestep   indirect_natural\n\n\n\nFrom the above, we can conclude that the effect of participation on a sports team on BMI is primarily mediated by the variables snack, exercises, and overweigh, as the natural indirect effect is several times larger than the natural direct effect.\nNote that we could have instead used the TML estimators, which have improved finite-sample performance, instead of the one-step estimators. Doing this is as simple as setting the estimator = \"tmle\" in the relevant argument.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Some `R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "estimation_walkthrough.html#interventional-indirect-effects",
    "href": "estimation_walkthrough.html#interventional-indirect-effects",
    "title": "\n6  Some R packages for estimation of the causal (in)direct effects\n",
    "section": "\n6.3 Interventional (in)direct effects",
    "text": "6.3 Interventional (in)direct effects\nSince our knowledge of the system under study is incomplete, we might worry that one (or more) of the measured variables are not mediators, but, in fact, intermediate confounders affected by treatment. While the natural (in)direct effects are not identified in this setting, their interventional (in)direct counterparts are, as we saw in an earlier section. Recall that both types of effects are defined by static interventions on the treatment. The interventional effects are distinguished by their use of a stochastic intervention on the mediator to aid in their identification.\n\n\n\n\nDirected acyclic graph under intermediate confounders of the mediator-outcome relation affected by treatment\n\n\n\nRecall that the interventional (in)direct effects are defined via the decomposition:\n\\[\n  \\E[Y_{1,G_1} - Y_{0,G_0}] =\n    \\underbrace{\\E[Y_{\\color{red}{1},\\color{blue}{G_1}} -\n    Y_{\\color{red}{1},\\color{blue}{G_0}}]}_{\\text{interventional indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{1},\\color{red}{G_0}} -\n    Y_{\\color{blue}{0},\\color{red}{G_0}}]}_{\\text{interventional direct effect}}\n\\]\n\nIn our data example, we’ll consider the eating of snacks as a potential intermediate confounder, since one might reasonably hypothesize that participation on a sports team might subsequently affect snacking, which then could affect mediators like the amount of exercises and overweight status.\nThe interventional direct and indirect effects may also be easily estimated with the medoutcon R package (Hejazi, Dı́az, and Rudolph 2022; Hejazi, Rudolph, and Dı́az 2022).\nJust as for the natural (in)direct effects, medoutcon implements cross-validated one-step and TML estimators of the interventional effects.\n\n\nHejazi, Nima S, Iván Dı́az, and Kara E Rudolph. 2022. “medoutcon: Efficient Natural and Interventional Causal Mediation Analysis.” https://doi.org/10.5281/zenodo.5809519.\n\nHejazi, Nima S, Kara E Rudolph, and Iván Dı́az. 2022. “medoutcon: Nonparametric Efficient Causal Mediation Analysis with Machine Learning in R.” Journal of Open Source Software. https://doi.org/10.21105/joss.03979.\n\n6.3.1 Efficient estimation of the interventional (in)direct effects\n\n\nEstimation of these effects is more complex, so a few additional nuisance parameters arise when expressing the (more general) EIF for these effects:\n\n\n\\(q(z \\mid a, w)\\), the conditional density of the intermediate confounders, conditional only on treatment and baseline covariates;\n\n\\(r(z \\mid a, m, w)\\), the conditional density of the intermediate confounders, conditional on mediators, treatment, and baseline covariates.\n\n\nTo estimate the interventional effects, we only need to set the argument Z of medoutcon to a value other than NULL.\nNote that the implementation in medoutcon is currently limited to settings with only binary intermediate confounders, i.e., \\(Z \\in \\{0, 1\\}\\).\n\nLet’s use medoutcon() to estimate the interventional direct effect:\n\nCode# compute one-step estimate of the interventional direct effect\ninterv_de_onestep &lt;- medoutcon(\n  W = weight_behavior[, c(\"age\", \"sex\", \"race\", \"tvhours\")],\n  A = (as.numeric(weight_behavior$sports) - 1),\n  Z = (as.numeric(weight_behavior$snack) - 1),\n  M = weight_behavior[, c(\"exercises\", \"overweigh\")],\n  Y = weight_behavior$bmi,\n  g_learners = lasso_lrnr,\n  h_learners = lasso_lrnr,\n  b_learners = lasso_lrnr,\n  effect = \"direct\",\n  estimator = \"onestep\",\n  estimator_args = list(cv_folds = 5)\n)\nsummary(interv_de_onestep)\n\n# A tibble: 1 × 7\n  lwr_ci param_est upr_ci var_est  eif_mean estimator param                \n   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                \n1 -0.362    0.0921  0.547  0.0538 -4.06e-16 onestep   direct_interventional\n\n\n\n\nWe can similarly estimate the interventional indirect effect:\n\nCode# compute one-step estimate of the interventional indirect effect\ninterv_ie_onestep &lt;- medoutcon(\n  W = weight_behavior[, c(\"age\", \"sex\", \"race\", \"tvhours\")],\n  A = (as.numeric(weight_behavior$sports) - 1),\n  Z = (as.numeric(weight_behavior$snack) - 1),\n  M = weight_behavior[, c(\"exercises\", \"overweigh\")],\n  Y = weight_behavior$bmi,\n  g_learners = lasso_lrnr,\n  h_learners = lasso_lrnr,\n  b_learners = lasso_lrnr,\n  effect = \"indirect\",\n  estimator = \"onestep\",\n  estimator_args = list(cv_folds = 5)\n)\nsummary(interv_ie_onestep)\n\n# A tibble: 1 × 7\n  lwr_ci param_est upr_ci var_est  eif_mean estimator param                  \n   &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;                  \n1  0.413     0.992   1.57  0.0872 -1.24e-15 onestep   indirect_interventional\n\n\n\nFrom the above, we can conclude that the effect of participation on a sports team on BMI is largely through the interventional indirect effect (i.e., through the pathways involving the mediating variables) rather than via its direct effect.\nJust as before, we could have instead used the TML estimators, instead of the one-step estimators. Doing this is as simple as setting the estimator = \"tmle\" in the relevant argument.",
    "crumbs": [
      "Estimation",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Some `R` packages for estimation of the causal (in)direct effects</span>"
    ]
  },
  {
    "objectID": "additional_readings.html",
    "href": "additional_readings.html",
    "title": "7  Appendix: Additional topics of interest",
    "section": "",
    "text": "7.1 Mediation with multiple mediators and multiple intermediate confounders\nNote that the medoutcon R package works for multiple mediators but is limited to settings with only a single, binary intermediate confounder. If your data scenario includes multiple mediators and multiple intermediate confounders, you should consider using the HDmediation R package instead.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "additional_readings.html#mediation-with-multiple-mediators-and-multiple-intermediate-confounders",
    "href": "additional_readings.html#mediation-with-multiple-mediators-and-multiple-intermediate-confounders",
    "title": "7  Appendix: Additional topics of interest",
    "section": "",
    "text": "Practical causal mediation analysis: extending nonparametric estimators to estimate the mediated effects of housing voucher receipt on adolescent risk behavior By Kara E. Rudolph, Nicholas Williams, and Iván Díaz",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "additional_readings.html#mediation-with-monotonicity-of-a-z-relationship",
    "href": "additional_readings.html#mediation-with-monotonicity-of-a-z-relationship",
    "title": "7  Appendix: Additional topics of interest",
    "section": "7.2 Mediation with monotonicity of A-Z relationship",
    "text": "7.2 Mediation with monotonicity of A-Z relationship\n\nOn identification of natural direct effects when a confounder of the mediator is directly affected by exposure by Eric J. Tchetgen Tchetgen and Tyler J. VanderWeele\nEfficient and flexible estimation of natural mediation effects under intermediate confounding and monotonicity constraints by Kara E. Rudolph and Iván Díaz",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "additional_readings.html#mediation-with-instrumental-variables",
    "href": "additional_readings.html#mediation-with-instrumental-variables",
    "title": "7  Appendix: Additional topics of interest",
    "section": "7.3 Mediation with instrumental variables",
    "text": "7.3 Mediation with instrumental variables\n\nDirect and indirect treatment effects–causal chains and mediation analysis with instrumental variables by Markus Frolich and Martin Huber\nCausal mediation with instrumental variables by Kara E. Rudolph, Nicholas Williams, and Iván Díaz",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "additional_readings.html#mediation-with-separable-effects",
    "href": "additional_readings.html#mediation-with-separable-effects",
    "title": "7  Appendix: Additional topics of interest",
    "section": "7.4 Mediation with separable effects",
    "text": "7.4 Mediation with separable effects\n\nAn Interventionist Approach to Mediation Analysis by James M. Robins, Thomas S. Richardson, and Ilya Shpitser\nConditional Separable Effects by Mats J. Stensrud, James M. Robins, Aaron Sarvet, Eric J. Tchetgen Tchetgen, and Jessica G. Young\nSeparable Effects for Causal Inference in the Presence of Competing Events by Mats J. Stensrud, Jessica G. Young, Vanessa Didelez, James M. Robins, and Miguel A. Hernán\nA Generalized Theory of Separable Effects in Competing Event Settings by Mats J. Stensrud, Miguel A. Hernán, Eric J. Tchetgen Tchetgen, James M. Robins, Vanessa Didelez, and Jessica G. Young",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Appendix: Additional topics of interest</span>"
    ]
  },
  {
    "objectID": "stochastic_effects.html",
    "href": "stochastic_effects.html",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "",
    "text": "8.1 Definition of the effects\nConsider the following directed acyclic graph.\nDirected acyclic graph under no intermediate confounders of the mediator-outcome relation affected by treatment",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "stochastic_effects.html#motivation-for-stochastic-interventions",
    "href": "stochastic_effects.html#motivation-for-stochastic-interventions",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.2 Motivation for stochastic interventions",
    "text": "8.2 Motivation for stochastic interventions\n\nSo far we have discussed controlled, natural, and interventional (in)direct effects\nThese effects require that \\(0 &lt; \\P(A=1\\mid W) &lt; 1\\)\n\nThey are defined only for binary exposures\nWhat can we do when the positivity assumption does not hold or the exposure is continuous?\nSolution: We can use stochastic effects",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "stochastic_effects.html#definition-of-stochastic-effects",
    "href": "stochastic_effects.html#definition-of-stochastic-effects",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.3 Definition of stochastic effects",
    "text": "8.3 Definition of stochastic effects\nThere are two possible ways of defining stochastic effects:\n\nConsider the effect of an intervention where the exposure is drawn from a distribution\n\nFor example incremental propensity score interventions\n\n\nConsider the effect of an intervention where the post-intervention exposure is a function of the actually received exposure\n\nFor example modified treatment policies\n\n\nIn both cases \\(A \\mid W\\) is a non-deterministic intervention, thus the name stochastic intervention\n\n\n\n8.3.1 Example: incremental propensity score interventions (IPSI) (Kennedy 2018)\n\n\nKennedy, Edward H. 2018. “Nonparametric Causal Effects Based on Incremental Propensity Score Interventions.” Journal of the American Statistical Association, no. just-accepted.\nDefinition of the intervention\n\nAssume \\(A\\) is binary, and \\(\\P(A=1\\mid W=w) = g(1\\mid w)\\) is the propensity score\nConsider an intervention in which each individual receives the intervention with probability \\(g_\\delta(1\\mid w)\\), equal to \\[\\begin{equation*}\n  g_\\delta(1\\mid w)=\\frac{\\delta g(1\\mid w)}{\\delta g(1\\mid w) +\n  1 - g(1\\mid w)}\n\\end{equation*}\\]\n\ne.g., draw the post-intervention exposure from a Bernoulli variable with probability \\(g_\\delta(1\\mid w)\\)\n\nThe value \\(\\delta\\) is user given\nLet \\(A_\\delta\\) denote the post-intervention exposure distribution\nSome algebra shows that \\(\\delta\\) is an odds ratio comparing the pre- and post-intervention exposure distributions \\[\\begin{equation*}\n  \\delta = \\frac{\\text{odds}(A_\\delta = 1\\mid W=w)}\n  {\\text{odds}(A = 1\\mid W=w)}\n\\end{equation*}\\]\n\nInterpretation: what would happen in a world where the odds of receiving treatment is increased by \\(\\delta\\)\n\nLet \\(Y_{A_\\delta}\\) denote the outcome in this hypothetical world\n\n8.3.1.1 Illustrative application for IPSIs\n\nConsider the effect of participation in sports on children’s BMI\nMediation through snacking, exercising, etc.\nIntervention: for each individual, increase the odds of participating in sports by \\(\\delta=2\\)\n\nThe post-intervention exposure is a draw \\(A_\\delta\\) from a Bernoulli distribution with probability \\(g_\\delta(1\\mid w)\\)\n\nExample: modified treatment policies (MTP) (Dı́az and Hejazi 2020)\n\n\nDı́az, Iván, and Nima S Hejazi. 2020. “Causal Mediation Analysis for Stochastic Interventions.” Journal of the Royal Statistical Society: Series B (Statistical Methodology) 82 (3): 661–83.\nDefinition of the intervention\n\nConsider a continuous exposure \\(A\\) taking values in the real numbers\nConsider an intervention that assigns exposure as \\(A_\\delta = A - \\delta\\)\n\nExample: \\(A\\) is pollution measured as \\(PM_{2.5}\\) and you are interested in an intervention that reduces \\(PM_{2.5}\\) concentration by some amount \\(\\delta\\)\n\n\n8.3.2 Mediation analysis for stochastic interventions\n\nThe total effect of an IPSI can be computed as a contrast of the outcome under intervention vs no intervention: \\[\\begin{equation*}\n  \\psi = \\E[Y_{A_\\delta} - Y]\n\\end{equation*}\\]\nRecall the NPSEM \\[\\begin{align*}\n  W & = f_W(U_W)\\\\\n  A & = f_A(W, U_A)\\\\\n  M & = f_M(W, A, U_M)\\\\\n  Y & = f_Y(W, A, M, U_Y)\n\\end{align*}\\]\nFrom this we have \\[\\begin{align*}\nM_{A_\\delta} & = f_M(W, A_\\delta, U_M)\\\\\nY_{A_\\delta} & = f_Y(W, A_\\delta, M_{A_\\delta}, U_Y)\n\\end{align*}\\]\nThus, we have \\(Y_{A_\\delta} = Y_{A_\\delta, M_{A_\\delta}}\\) and \\(Y =\nY_{A,M_{A}}\\)\nLet us introduce the counterfactual \\(Y_{A_\\delta, M}\\), interpreted as the outcome observed in a world where the intervention on \\(A\\) is performed but the mediator is fixed at the value it would have taken under no intervention: [Y_{A_, M} = f_Y(W, A_, M, U_Y)]\nThen we can decompose the total effect into: \\[\\begin{align*}\n  \\E[Y&_{A_\\delta,M_{A_\\delta}} - Y_{A,M_A}] = \\\\\n  &\\underbrace{\\E[Y_{\\color{red}{A_\\delta},\\color{blue}{M_{A_\\delta}}} -\n    Y_{\\color{red}{A_\\delta},\\color{blue}{M}}]}_{\\text{stochastic natural\n      indirect effect}} +\n    \\underbrace{\\E[Y_{\\color{blue}{A_\\delta},\\color{red}{M}} -\n    Y_{\\color{blue}{A},\\color{red}{M}}]}_{\\text{stochastic natural direct\n      effect}}\n\\end{align*}\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "stochastic_effects.html#identification-assumptions",
    "href": "stochastic_effects.html#identification-assumptions",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.4 Identification assumptions",
    "text": "8.4 Identification assumptions\n\nConfounder assumptions:\n\n\\(A \\indep Y_{a,m} \\mid W\\)\n\\(M \\indep Y_{a,m} \\mid W, A\\)\n\n\nNo confounder of \\(M\\rightarrow Y\\) affected by \\(A\\)\n\nPositivity assumptions:\n\nIf \\(g_\\delta(a \\mid w)&gt;0\\) then \\(g(a \\mid w)&gt;0\\)\n\nIf \\(\\P(M=m\\mid W=w)&gt;0\\) then \\(\\P(M=m\\mid A=a,W=w)&gt;0\\)\n\n\n\n\nUnder these assumptions, stochastic effects are identified as follows\n\nThe indirect effect can be identified as follows \\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, W)\n  -\\E(Y\\mid A=a, M, W)\\}}g_\\delta(a\\mid W)}\\right]\n\\end{align*}\\]\nThe direct effect can be identified as follows \\[\\begin{align*}\n\\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n&\\E\\left[\\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, M, W)\n  - Y\\}}g_\\delta(a\\mid W)}\\right]\n\\end{align*}\\]\n\nLet’s dissect the formula for the indirect effect in R:\n\nCoden &lt;- 1e6\nw &lt;- rnorm(n)\na &lt;- rbinom(n, 1, plogis(1 + w))\nm &lt;- rnorm(n, w + a)\ny &lt;- rnorm(n, w + a + m)\n\n\n\n\nFirst, fit regressions of the outcome on \\((A,W)\\) and \\((M,A,W)\\):\n\nCodefit_y1 &lt;- lm(y ~ m + a + w)\nfit_y2 &lt;- lm(y ~ a + w)\n\n\n\n\nGet predictions fixing \\(A=a\\) for all possible values \\(a\\)\n\nCodepred_y1_a1 &lt;- predict(fit_y1, newdata = data.frame(a = 1, m, w))\npred_y1_a0 &lt;- predict(fit_y1, newdata = data.frame(a = 0, m, w))\npred_y2_a1 &lt;- predict(fit_y2, newdata = data.frame(a = 1, w))\npred_y2_a0 &lt;- predict(fit_y2, newdata = data.frame(a = 0, w))\n\n\n\n\nCompute [] for each value \\(a\\)\n\nCodepseudo_a1 &lt;- pred_y2_a1 - pred_y1_a1\npseudo_a0 &lt;- pred_y2_a0 - pred_y1_a0\n\n\n\n\nEstimate the propensity score \\(g(1\\mid w)\\) and evaluate the post-intervention propensity score \\(g_\\delta(1\\mid w)\\)\n\nCodepscore_fit &lt;- glm(a ~ w, family = binomial())\npscore &lt;- predict(pscore_fit, type = 'response')\n## How do the intervention vs observed propensity score compare\npscore_delta &lt;- 2 * pscore / (2 * pscore + 1 - pscore)\n\n\n\n\nWhat do the post-intervention propensity scores look like?\n\nCodeplot(pscore, pscore_delta, xlab = 'Observed prop. score',\n     ylab = 'Prop. score under intervention')\nabline(0, 1)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "stochastic_effects.html#what-are-the-odds-of-exposure-under-intervention-vs-real-world",
    "href": "stochastic_effects.html#what-are-the-odds-of-exposure-under-intervention-vs-real-world",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.5 What are the odds of exposure under intervention vs real world?",
    "text": "8.5 What are the odds of exposure under intervention vs real world?\n\nCodeodds &lt;- (pscore_delta / (1 - pscore_delta)) / (pscore / (1 - pscore))\nsummary(odds)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      2       2       2       2       2       2 \n\n\n\n\nCompute the sum \\[\\begin{equation*}\n  \\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, W) -\n    \\E(Y\\mid A=a, M, W)\\}}g_\\delta(a\\mid W)}\n\\end{equation*}\\]\n\nCodeindirect &lt;- pseudo_a1 * pscore_delta + pseudo_a0 * (1 - pscore_delta)\n\n\n\n\nThe average of this value is the indirect effect\n\nCode## E[Y(Adelta) - Y(Adelta, M)]\nmean(indirect)\n\n[1] 0.1094722\n\n\n\nThe direct effect is \\[\\begin{align*}\n  \\E&(Y_{A_\\delta} - Y_{A_\\delta, M}) =\\\\\n  &\\E\\left[\\color{Goldenrod}{\\sum_{a}\\color{ForestGreen}{\\{\\E(Y\\mid A=a, M,\n    W) - Y\\}}g_\\delta(a\\mid W)}\\right]\n\\end{align*}\\]\n\nWhich can be computed as\n\nCodedirect &lt;- (pred_y1_a1 - y) * pscore_delta +\n       (pred_y1_a0 - y) * (1 - pscore_delta)\nmean(direct)\n\n[1] 0.1092223",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "stochastic_effects.html#summary",
    "href": "stochastic_effects.html#summary",
    "title": "8  Appendix: Stochastic direct and indirect effects",
    "section": "\n8.6 Summary",
    "text": "8.6 Summary\n\nStochastic (in)direct effects\n\nRelax the positivity assumption\nCan be defined for non-binary exposures\nDo not require a cross-world assumption\n\n\nStill require the absence of intermediate confounders\n\nBut, compared to the NDE and NIE, we can design a randomized study where identifiability assumptions hold, at least in principle\nThere is a version of these effects that can accommodate intermediate confounders (Hejazi et al. 2022)\n\n\nR implementation to be released soon…stay tuned!\n\n\n\n\n\n\n\n\nHejazi, Nima S, Kara E Rudolph, Mark J van der Laan, and Iván Dı́az. 2022. “Nonparametric Causal Mediation Analysis for Stochastic Interventional (in) Direct Effects.” Biostatistics (in press). https://doi.org/10.1093/biostatistics/kxac002.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Appendix: Stochastic direct and indirect effects</span>"
    ]
  },
  {
    "objectID": "longitudinal.html",
    "href": "longitudinal.html",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "",
    "text": "9.1 Illustrative example\nAs an illustrative example, we will use a dataset from an observational study looking at the effect of invasive mechanical ventilation (IMV) on the survival of COVID-19 patients, considering acute kidney injury (AKI) as a mediating factor.\nBriefly, IMV is a treatment for acute respiratory distress syndrome (ARDS). While IMV is a potentially life-saving therapy in patients with ARDS, its usage has been associated with several iatrogenic risks. Of interest to our illustrative study is acute kidney injury (AKI), a critical condition that complicates ICU stays and is associated with increased mortality. The causal model underlying this problem is as follows:\nThe data on a single observational unit can be represented by the vector \\(O=(L_1,\nA_1, Z_1, M_1, L_2, \\ldots, A_\\tau, Z_\\tau, M_\\tau, Y)\\), with the data pooled across all participants denoted \\(O_1, \\ldots, O_n\\), for a of \\(n\\) i.i.d. observations of \\(O\\). The associated DAG is\nDirected acyclic graph for time-varying treatments, mediators, and confounders\nWhere we are using the following notation:",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  },
  {
    "objectID": "longitudinal.html#illustrative-example",
    "href": "longitudinal.html#illustrative-example",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "",
    "text": "\\(W\\): baseline variables such as comorbidities, demographics, etc.\n\n\\(L_t\\) and \\(Z_t\\): time-varying covariates such as lab results, vitals, treatments, etc.\n\n\\(A_t\\): type of oxygen support at time \\(t\\) (0: no oxygen support, 1: oxygen support excluding IMV, 2: IMV)\n\n\\(M_t\\): indicator of AKI at time \\(t\\)\n\n\n\\(Y\\): mortality at end of study\nWe will use \\(H_t\\) as a shorthand to denote all the data measured up until right before \\(A_t\\) occurs",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  },
  {
    "objectID": "longitudinal.html#defining-causal-effects-in-this-example",
    "href": "longitudinal.html#defining-causal-effects-in-this-example",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "\n9.2 Defining causal effects in this example",
    "text": "9.2 Defining causal effects in this example\nHow can we define (total) causal effects in this example?\n\nMain challenge: cannot consider static treatmemt regimes (e.g., do not intubate)\nSuch regimes would not be supported in the data (doctors would always intubate a person whose blood oxygen is too low)\nWe use modified treatment policies to address this\nMain idea: consider a slight modification to the treatment a patient actually received\nFor example, can consider the effect of a small delay in receiving IMV\nSpecifically, we will consider a delay of one day in receiving IMV\nIn notation, the treatment regime would be as follows:\n\n\\[\\begin{equation}\n  d_t(a_t,h_t) =\n  \\begin{cases}\n    1 &\\text{ if } a_t=2 \\text{ and } a_s \\leq 1 \\text{ for all } s &lt; t,\\\\\n    a_t & \\text{ otherwise.}\n  \\end{cases}\n\\end{equation}\\] - We could then define the total effect as \\(E[Y(d) - Y]\\), where \\(Y(d)\\) is the counterfactual mortality if the above rule had been implemented every day, i.e., the intervention is \\(d=(d_1,d_2,\\ldots,\n  d_\\tau)\\). - This is a contrast of the mortality rate under a treatment rule that would delay intubation by one day vs the mortality rate that was actually observed.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  },
  {
    "objectID": "longitudinal.html#how-do-we-define-mediation-causal-effects-with-time-varying-data",
    "href": "longitudinal.html#how-do-we-define-mediation-causal-effects-with-time-varying-data",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "\n9.3 How do we define mediation causal effects with time-varying data?",
    "text": "9.3 How do we define mediation causal effects with time-varying data?\nThe above causal effect could be decomposed into natural direct and indirect effects as follows\n\\[\\begin{align*}\nE[Y(d) - Y] & = E[Y(d, M(d)) - Y(A, M)]\\\\\n&=\\underbrace{\\E[Y(\\color{red}{d},\\color{blue}{M(d)}) -\n    Y(\\color{red}{d},\\color{blue}{M})]}_{\\text{natural indirect effect}} +\n    \\underbrace{\\E[Y(\\color{blue}{d},\\color{red}{M}) -\n    Y(\\color{blue}{A},\\color{red}{M})]}_{\\text{natural direct effect}}\n\\end{align*}\\]\n\nHowever, as before, these natural mediation effects are not identified.\nThe reason is that time-varying mediators exacerbate the issue of intermediate confounding. To see why, let us look at the DAG again:\n\n\n\n\n\nDirected acyclic graph with intermediate confounding\n\n\n\nNote that all the variables in orange are confounders of the mediator \\(M_\\tau\\) and the outcome, and are also affected by treatment at time \\(t=2\\).\nOne possible solution to the above issues involves considering randomized versions of the above effects. Specifically:\n\nDefine \\(G(d)\\) to be a random draw from the distribution of \\(M(d)\\) conditional on baseline variables \\(W\\).\nWe can then obtain the decomposition \\[\n  \\E[Y(d, G(d)) - Y(A, G(A))]=\\underbrace{\\E[Y(\\color{red}{d},\\color{blue}{G(d)}) -\n  Y(\\color{red}{d},\\color{blue}{G(A)})]}_{\\text{randomized interventional indirect effect}} +\n  \\underbrace{\\E[Y(\\color{blue}{d},\\color{red}{G(A)}) -\n    Y(\\color{blue}{A},\\color{red}{G(A)})]}_{\\text{randomized interventional\n      direct effect}}\n\\]\n\nAs an example, consider the counterfactual \\(Y(d, G(d))\\).\n\n\\(M(d)\\) is the observed AKI status of patients under a delay in intubation. If \\(W\\) is age, and we are deciding how to intervene on a patient who is 45 years old, we take all the AKI statuses of 45 year olds and draw one of these AKI values at random. Call this random draw \\(G(d)\\)\n\nFor a 45 year old patient, \\(Y(d, G(d))\\) is the counterfactual mortality of a patient if intubation had been delayed, and their AKI status would have been assigned to a random draw from the AKI status of 45 year patients.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  },
  {
    "objectID": "longitudinal.html#identification-assumptions-and-formula",
    "href": "longitudinal.html#identification-assumptions-and-formula",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "\n9.4 Identification assumptions and formula",
    "text": "9.4 Identification assumptions and formula\nThe above effects are identified under the following assumptions:\n\nAll the common causes of \\(A_t\\) and \\((Z_s, M_s, A_{s+1}, L_{s+1})\\) are measured for \\(s\\geq t\\)\n\nAll the common causes of \\(M_t\\) and \\((Z_{s+1}, A_{s+1}, L_{s+1})\\) are measured for \\(s\\geq t\\)\n\nThe intervention \\(d\\) is supported in the data, meaning that for every patient with covariates \\(h_t\\) who had treatment status \\(a_t\\), it is possible to find a patient with covariates \\(h_t\\) who had treatment status \\(d(a_t, h_t)\\)\n\nIn our example, this translates roughly as: for every patient with covariate history \\(h_t\\) who was intubated at time \\(t\\), it is possible to find a patient covariate history \\(h_t\\) who was intubated at time \\(t+1\\).\n\n\nThere is a positive probability of the mediator \\(M_t\\) for all feasible covariate histories.\n\nThe identification formula is complex, but we will explain it in the case of two time points. That is, assume the data are \\(O=(W, A_1, Z_1, M_1, L_1, A_2,\nZ_2, M_2, Y)\\).\nIdentification can be based on the following procedure. First, for each value \\(m_1\\) and \\(m_2\\) of the mediator, compute outcome regressions as follows:\n\nRegress \\(Y\\) on \\(W, A_1, Z_1, M_1, L_1, A_2, Z_2, M_2\\). Use this regression to predict the outcome had the mediator been set to \\(M_2=m_2\\). Let \\(\\tilde Y_2(m_2)\\) denote this prediction.\nRegress \\(\\tilde Y_2(m_2)\\) on \\(W, A_1, Z_1, M_1, L_1, A_2\\). Use this regression to predict the outcome had the treatment \\(A_2\\) been set to \\(d(A_2, H_2)\\). Let \\(\\tilde Y_2^d(m_2)\\) denote this prediction.\nRegress \\(\\tilde Y_2(m_2, d_2)\\) on \\(W, A_1, Z_1, M_1\\). Use this regression to predict the outcome had the mediator been set to \\(M_1=m_1\\). Let \\(\\tilde Y_1(m_1, m_2)\\) denote this prediction.\nRegress \\(\\tilde Y_1(m_1, m_2)\\) on \\(W, A_1\\). Use this regression to predict the outcome had the treatment \\(A_1\\) been set to \\(d(A_1, H_1)\\). Let \\(\\tilde Y_1^d(m_1, m_2)\\) denote this prediction.\n\nThen, for each value \\(m_1\\) and \\(m_2\\) of the mediator, compute the mediator distribution as follows:\n\nRegress the binary variable \\(I(M_2=m_2)\\) on \\(W, A_1, Z_1, M_1, L_1, A_2\\). Use this model to predict the probability of \\(M_2=m_2\\) under an intervention that sets \\(A_2\\) to \\(d(A_2, H_2)\\). Let this predicted probability be denoted with \\(P(m_2)\\).\nRegress the binary variable \\(I(M_1=m_1)P(m_2)\\) on \\(W, A_1\\). Use this model to predict under an intervention that sets \\(A_1\\) to \\(d(A_1, H_1)\\). Let this prediction be denoted with \\(P(m_1, m_2)\\).\n\nAt the end of these two sequential regression procedures, we have values \\(\\tilde Y_1^d(m_1, m_2)\\) and \\(P(m_1, m_2)\\) for each value of the mediator \\((m_1, m_2)\\). Then, under identification assumptions, we have:\n\\[\n  \\E[Y(d, G(d)) = \\sum_{m_1, m_2}\\tilde Y_1^d(m_1, m_2)P(m_1, m_2) \\ .\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  },
  {
    "objectID": "longitudinal.html#estimators-and-r-package",
    "href": "longitudinal.html#estimators-and-r-package",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "\n9.5 Estimators and R package",
    "text": "9.5 Estimators and R package\nAs before, we can develop inverse probability weighted estimators, as well as substitution estimators based on the g-computation formula and doubly robust (DR) estimators.\nAll of these estimators get significantly more complex. For instance, an g-computation estimator may be developed by running the regressions indicated in the above sequential regression procedures.\nFortunately, the doubly robust estimators are coded in a package that can be used off-the-shelf without having to code any complicated sequential regression strategies on your own. Let us look at an example from the lcmmtp R package. First, let’s take a look at a simulated dataset available in the package:\n\nCodelibrary(lcmmtp)\ndata &lt;- as.data.frame(apply(lcmmtp_foo, 2, as.numeric))\nhead(data)\n\n  ID L_1 A_1 Z_1 M_1 L_2 A_2 Z_2 M_2  Y c1 c2\n1  1   2   1   2   1   2   0   1   3 NA  1  0\n2  2   2   1   2   2   1   0   1   3  0  1  1\n3  3   1   0   2   2   3   1   2   3  0  1  1\n4  4   1   0   3   2   3   1   1   2  1  1  1\n5  5   1   0   1   2   2   1   1   2  1  1  1\n6  6   1   0   3   2   1   1   3   2  0  1  1\n\nCodedim(lcmmtp_foo)\n\n[1] 5000   12\n\n\nNow, let us perform an analysis where we assume our intent is to estimate \\(\\E[Y(1), G(0)]\\):\n\nCodelibrary(mlr3extralearners)\nvars &lt;- lcmmtp:::lcmmtp_variables$new(\n    L = list(c(\"L_1\"), c(\"L_2\")),\n    A = c(\"A_1\", \"A_2\"),\n    Z = list(c(\"Z_1\"), c(\"Z_2\")),\n    M = c(\"M_1\", \"M_2\"),\n    Y = \"Y\",\n    cens = c(\"c1\", \"c2\")\n)\nlrnrs &lt;- c(\"mean\", \"earth\", \"glm\")\nd_ap &lt;- function(data, trt) rep(1, length(data[[trt]]))\nd_as &lt;- function(data, trt) rep(0, length(data[[trt]]))\n\nEY10 &lt;- lcmmtp(\n  data, vars, d_ap, d_as,\n  control = .lcmmtp_control(folds = 2,\n                            learners_trt = lrnrs,\n                            learners_mediator = lrnrs,\n                            learners_QL = lrnrs,\n                            learners_QZ = lrnrs,\n                            learners_QM = lrnrs)\n)\n\n\nNow, assume that we want to estimate the direct effect by contrasting \\(\\E[Y(1), G(0)] - \\E[Y(0), G(0)]\\):\n\nCodeEY00 &lt;- lcmmtp(\n  lcmmtp_foo, vars, d_as, d_as,\n  control = .lcmmtp_control(folds = 2,\n                            learners_trt = lrnrs,\n                            learners_mediator = lrnrs,\n                            learners_QL = lrnrs,\n                            learners_QZ = lrnrs,\n                            learners_QM = lrnrs)\n)\n\n\nAnd we can contrast the two using a convenient function from the lmtp R package:\n\nCodelibrary(lmtp)\nclass(EY00) &lt;- class(EY10) &lt;- 'lmtp'\nEY00$estimator &lt;- EY10$estimator &lt;- 'SDR'\nnames(EY00)[3] &lt;- names(EY10)[3] &lt;- 'eif'\nlmtp_contrast(EY10, ref = EY00)\n\n\n  \n    theta shift   ref std.error conf.low conf.high p.value\n1 -0.0166 0.405 0.421    0.0184  -0.0527    0.0195   0.368",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  },
  {
    "objectID": "longitudinal.html#pros-and-cons-of-this-methodology",
    "href": "longitudinal.html#pros-and-cons-of-this-methodology",
    "title": "\n9  Mediation with time-varying treatments, mediators, and covariates\n",
    "section": "\n9.6 Pros and cons of this methodology",
    "text": "9.6 Pros and cons of this methodology\nPros\n\nAllows the non-parametric definition, identification, and estimation of mediational causal effects for general longitudinal data structures\nAllows for the use of machine learning to alleviate model misspecification bias, and is equipped with formulas for the computation of correct standard errors and confidence intervals\nEasy-to-use software\nCons\n\nSome limitations remain: mediators \\(M\\) need to be discrete random variables\nAs before, interventional effects do not satisfy the mediational sharp null criteria, meaning that they may be different from zero when no individual in the population experiences mediational effects\n\nThis is probably not a big worry in practice, but it is something we are keeping in mind as we develop novel estimators",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Mediation with time-varying treatments, mediators, and covariates</span>"
    ]
  }
]